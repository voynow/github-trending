query,repo,similar_documents,text,score,query_id
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,modal-client
openai
tiktoken,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is a human-centric and coherent whole program synthesis tool that uses AI to help developers in their workflow. The codebase is simple, safe, and small, making it easy to understand and customize. The tool uses prompts to generate code, and the human can add to the prompt as they discover underspecified parts of it. The AI is only used as long as it is adding value, and once it gets in the way, the human can take over the codebase from the junior developer with no fuss. The tool is not no code or low code, but some third thing that still requires technical knowledge. The repository also contains a video demo and an arch diagram. To install, you need to clone the repository and fill in your API keys. The tool uses Modal as a self-provisioning runtime and requires access to Modal.com, GPT-4 API, and anthropic claude 100k context API, which are currently in private beta. The tool uses Markdown to prompt for whole program synthesis and allows for copy and paste programming, debugging by catting the whole codebase, and tricks for whole program coherence.",90,0
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. It is designed to be helpful, harmless, and honest, with a codebase that is simple, safe, and small. The program uses prompts to generate code, which can be manually run and modified by the user. The goal is to create a higher order evolution of programming where developers still need to be technical, but no longer have to implement every detail to scaffold things out. The repository also includes a video demo and an arch diagram. To use the program, users need to clone the repository and fill in their API keys. The program uses Modal as a self-provisioning runtime and requires access to the GPT-4 API and the anthropic claude 100k context API. The repository also includes an example Chrome extension that summarizes web pages using the Anthropic Claude API.",70,1
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. It is designed to be helpful, harmless, and honest, with a codebase that is simple, safe, and small. The program uses prompts to generate code, which can be manually run and modified by the user. The repository includes a video demo and installation instructions, but requires access to private beta APIs. The example project is a Chrome extension that summarizes web pages using the Anthropic Claude API.",90,2
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase for you based on a product spec. It is designed to be helpful, harmless, and honest, with a codebase that is simple, safe, and small. The program uses prompts to generate code, which can be manually run and modified by the user. The repository includes a video demo and installation instructions. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API, and consists of several files including popup.js, styles.css, background.js, popup.html, shared_dependencies.md, and content_script.js.",70,3
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. It is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and small. The program uses prompts to generate code, and the user can manually run and read the code, add to the prompt, and paste error messages into the prompt. The program is designed to be used until it is no longer adding value, at which point the user can take over the codebase. The repository also includes a video demo and an arch diagram. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API, and uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface.",50,4
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,modal-client
openai
tiktoken,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is a human-centric and coherent whole program synthesis tool that uses prompts to generate code. The AI is only used as long as it is adding value, and once it gets in your way, you can take over the codebase from your smol junior developer with no fuss and no hurt feelings. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. The repository also contains a video demo and an arch diagram. To install, you need to clone the repository and fill in your API keys. The project uses Modal.com, GPT-4 API, and anthropic claude 100k context API, which are all private beta. The repository also contains some innovations and insights, such as using Markdown to prompt for whole program synthesis and debugging by `cat`ing the whole codebase with your error message and getting specific fix suggestions.",90,5
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. It is designed to be helpful, harmless, and honest, with a codebase that is simple, safe, and small. The program uses prompts to generate code, and the user can manually run and identify errors, or paste errors into the prompt for suggestions. The program is not no-code or low-code, but a third thing that still requires technical knowledge. The repository includes a video demo and installation instructions. One example project is a Chrome extension that summarizes web pages using the Anthropic Claude API.",90,6
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase for you based on a product spec. It is a human-centric and coherent whole program synthesis tool that uses prompts to generate code. The codebase is simple, safe, and small, making it easy to understand and customize. The AI is helpful, harmless, and honest, and is only used as long as it adds value. The demo example shows the potential of AI-enabled, but still firmly human developer-centric, workflow. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages.",70,7
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken","To use the smol-ai/developer repository for your own projects, you can clone the repository and copy the .example.env file to .env, filling in your API keys. There are no Python dependencies to worry about thanks to the use of Modal as a self-provisioning runtime. However, the project does use three waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API, which are all private beta. You can run the project without Modal by following the instructions in the repository. If you want to use the code on other infrastructures, you'll need to adapt it on a fork. The repository also contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase for you once you give it a product spec. The codebase is simple, safe, and small, making it easy to understand and customize.",80,8
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is a human-centric and coherent whole program synthesis tool that uses prompts to generate code. The codebase is simple, safe, and small, with less than 200 lines of Python and Prompts. The AI is only used as long as it is adding value, and once it gets in your way, you can take over the codebase from your smol junior developer with no fuss and no hurt feelings. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages.",50,9
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, 
background.js, popup.html, shared_dependencies.md, and content_script.js. 

popup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic
for the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides 
styling for the UI elements.

background.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for 
processing. It also handles storing and retrieving the page content data using Chrome's storage API.

shared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.

Overall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the 
Anthropic Claude API.","This github repository contains a prototype for a ""junior developer"" agent that scaffolds an entire codebase for you based on a product spec. It is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and small. The program uses prompts to generate code, and the user can add to the prompt as they discover underspecified parts of it. The AI is only used as long as it is adding value, and the user can take over the codebase from the junior developer at any time. The program is not no code or low code, but some third thing. It is a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail to scaffold things out. The repository also contains a video demo and an arch diagram. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API and uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface.",70,10
Explain this to me like I'm 5.,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,modal-client
openai
tiktoken,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is a human-centric and coherent whole program synthesis tool that uses AI to help developers create codebases quickly and easily. The codebase is simple, safe, and small, making it easy to understand and customize. The tool uses prompts to generate code, and the human can add to the prompt as they discover underspecified parts of the prompt. The AI is only used as long as it is adding value, and once it gets in your way, you can take over the codebase from your smol junior developer with no fuss and no hurt feelings. The tool is not no code, not low code, but some third thing, where you still need to be technical, but no longer have to implement every detail to scaffold things out. The repository also contains a video demo and an arch diagram.",90,11
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in the smol-ai/developer repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The code uses prompts written in Markdown to generate code, and the user can add to the prompt as they discover underspecified parts. The codebase is designed to be simple, safe, and under 200 lines of Python and Prompts. The code also has the ability to install its own dependencies and self-heal by using errors as information for reprompting. The code is meant to be helpful, harmless, and honest, and is a prototype for a new way of programming that is human-centric and coherent.",90,0
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in the smol-ai/developer repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses prompts written in Markdown to generate code, which the user can then manually run and modify as needed. The codebase is designed to be simple, safe, and less than 200 lines of Python and Prompts. The repository also contains information on how to avoid dependency issues and how to use anthropic as the coding layer. The code is meant to be helpful, harmless, and honest, and is focused on whole program synthesis using prompts rather than prompt engineering.",90,1
What does this do?,https://github.com/smol-ai/developer,"- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","## Key Features of smol-ai/developer Repository and Their Utilization

The smol-ai/developer repository offers a unique approach to programming by utilizing AI to generate code based on prompts written in Markdown. The key features of this repository include:

- Markdown-based prompts: Markdown is used to prompt for whole program synthesis, allowing for easy mixing of English and code. Prompts can be specified in code, and GPT4 follows them to the letter.
- Copy and paste programming: The program can be taught to understand how to code around a new API by pasting in the `curl` input and output or error messages into the prompt. This approach is similar to ""logbook driven programming.""
- Debugging by `cat`ing: The entire codebase can be `cat`ed with an error message to get specific fix suggestions.
- Tricks for whole program coherence: The repository provides a solution for indirect dependencies across files by adding an intermediate step asking GPT to think through `shared_dependencies.md` and then insisting on using that in generating each file. However, `shared_dependencies.md` is not always comprehensive in understanding hard dependencies between files, so specifying a specific name in the prompt is sometimes necessary.
- Low activation energy for unfamiliar APIs: Users can add to the prompt as they discover underspecified parts of the prompt, manually run the code and identify errors, and paste the error into the prompt just like filing a GitHub issue. For extra help, `debugger.py` can be used to make specific code change suggestions.
- Ability to install its own dependencies: The repository can install its own dependencies, but this can lead to dependency madness. Dockerize, Nix, or a web container may be used to avoid this issue.
- Self-heal: The program can run itself and use errors as information for reprompting.
- Using Anthropics as the coding layer: Anthropics can be used to generate code, but it doesn't follow instructions to generate file code very well.
- Make agents that autonomously run this code: Agents can be made to run the code in a loop and regenerate code each time on a new git branch.

Overall, the smol-ai/developer repository offers a new approach to programming that combines human and AI intelligence. It is not a no-code or low-code solution, but rather a third way that still requires technical knowledge.",90,2
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in this repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses prompts written in Markdown to generate code, which the user can then manually run and modify as needed. The codebase is designed to be simple, safe, and under 200 lines of Python and Prompts. The agent can also make specific code change suggestions using a tool called `debugger.py`. The codebase is intended to be human-centric and to complement AI that is helpful, harmless, and honest. The repository contains various documents that provide additional information on the codebase, including a video demo and an arch diagram.",90,3
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in this repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses prompts written in Markdown to generate code and can be manually adjusted by the user as needed. The codebase is designed to be simple, safe, and less than 200 lines of Python and Prompts. The agent can also self-heal by using errors as information for reprompting. The codebase is designed to be human-centric and coherent, with a focus on whole program synthesis. The repository contains a video demo and an architecture diagram, as well as information on the ability to install dependencies, using anthropic as the coding layer, and making agents that autonomously run the code in a loop.",90,4
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in the smol-ai/developer repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The code uses prompts written in Markdown to generate code, and the user can add to the prompt as they discover underspecified parts. The codebase is designed to be simple, safe, and under 200 lines of Python and Prompts. The code also has the ability to install its own dependencies and self-heal by using errors as information for reprompting. The ultimate goal is to create a human-centric and coherent whole program synthesis that is easy to understand and customize.",90,5
What does this do?,https://github.com/smol-ai/developer,"- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","## Key Features of the smol-ai/developer Repository and Their Utilization

The smol-ai/developer repository offers a unique approach to programming that combines human input with AI-generated code. Key features of this repository include the use of Markdown for program synthesis prompts, copy and paste programming for new APIs, debugging by ""cat""ing the codebase with error messages, and tricks for whole program coherence. Additionally, the repository allows for low activation energy for unfamiliar APIs, self-healing through error messages, and the ability to install its own dependencies.

Users can utilize these features by adding prompts to the codebase, pasting error messages into the prompt, and manually running the code to identify errors. The repository also offers the ability to generate functions that speak modal and make agents that autonomously run the code in a loop. However, it is important to note that the AI is only used as long as it adds value and can be taken over by the user at any time.

Overall, the smol-ai/developer repository offers a new approach to programming that combines human input with AI-generated code, allowing for a higher order evolution of programming where users still need to be technical but no longer have to implement every detail.",90,6
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in this repository is to provide a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses prompts written in Markdown to generate code, which the user can then run and modify as needed. The codebase is designed to be simple, safe, and small, with less than 200 lines of Python and prompts. The agent can also use AI to suggest specific code changes and can self-heal by using errors as information for reprompting. The codebase is licensed under the MIT License.",90,7
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in this repository is to provide a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses AI to generate code based on prompts written in Markdown, and the user can add to the prompts as they discover underspecified parts. The codebase is kept simple and customizable, with less than 200 lines of Python and Prompts. The agent can also suggest specific code changes using a debugger. The code is designed to be helpful, harmless, and honest, and is intended to be used until it no longer adds value. The repository contains additional information on the use of Markdown for prompting, copy and paste programming, and debugging.",90,8
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.","This repository contains a prototype for a ""junior developer"" agent called smol-dev that can scaffold an entire codebase based on a product spec. The agent uses AI to generate code based on prompts written in Markdown. The code can be manually reviewed and errors can be pasted back into the prompt for further refinement. The repository also includes a debugger tool that can suggest specific code changes based on the entire codebase. The codebase is designed to be simple, safe, and less than 200 lines of Python and Prompts. The repository is licensed under the MIT License.",90,9
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in the smol-ai/developer repository is to provide a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The codebase is kept simple and small, and the workflow is human-centric, with the user writing prompts in Markdown and the AI generating code based on those prompts. The AI is only used as long as it adds value, and the user can take over the codebase at any time. The codebase is designed to be easy to understand and customize, with fewer than 200 lines of Python and prompts. The codebase also includes features such as the ability to install its own dependencies, self-healing by running the code itself and using errors as information for reprompting, and the ability to make agents that autonomously run the code in a loop and regenerate code each time. The codebase is designed to be a higher order evolution of programming, where the user still needs to be technical but no longer has to implement every detail to scaffold things out.",90,10
What does this do?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The purpose of the code in this repository is to create a ""junior developer"" agent that can scaffold an entire codebase based on a product spec provided by the user. The agent uses prompts written in Markdown to generate code, which the user can then manually run and modify as needed. The codebase is designed to be simple, safe, and under 200 lines of Python and Prompts. The agent can also make specific code change suggestions using a tool called `debugger.py`. The codebase is intended to be human-centric and to complement AI in a helpful, harmless, and honest way. The repository contains various documents that provide insights into the development process and innovations used in the codebase.",90,11
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal.com, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy the .example.env file and fill in the API keys before running the project. The project does not have any Python dependencies to manage thanks to the use of Modal as a self-provisioning runtime. However, the project uses three private beta services, including Modal.com, which requires an invite from the Modal team to access. The project can be run without Modal by following the instructions in the repository.",90,0
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png","The .env file in the smol-ai/developer repository contains API keys for Modal and Anthropics, which are used in the code. It is necessary to copy the .example.env file and fill in the API keys to use the project. The codebase is designed to be simple and customizable, with a focus on human-centric and coherent whole program synthesis. The project uses AI to scaffold an entire codebase based on a product spec provided by the user, and the user can add to the prompt as they discover underspecified parts. The project is still in prototype stage and requires access to private beta APIs for Modal and Anthropics. There are no Python dependencies to manage thanks to the use of Modal as a self-provisioning runtime. The project is not specific to any particular infrastructure and can be adapted on a fork.",80,1
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal.com, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy over the .example.env file and fill in the API keys to use the project. The project does not have any Python dependencies to manage thanks to using Modal as a self-provisioning runtime. However, the project also uses three private beta services, so it may be necessary to adapt the code on a fork to use it on other infrastructures.",90,2
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png","The .env file in the smol-ai/developer repository contains API keys for Modal and Anthropics, which are used in the code. It is created by copying over the .example.env file and filling in the necessary keys. The codebase is a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. The project uses Modal as a self-provisioning runtime and requires access to the GPT-4 and Anthropics APIs, which are currently in private beta. The codebase is simple, safe, and less than 200 lines of Python and Prompts. The project is designed to be human-centric and complemented by AI that is helpful, harmless, and honest.",90,3
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal.com, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy the .example.env file and fill in the API keys before running the project. The project does not have any Python dependencies to install. However, it requires access to private beta APIs, which may require waitlisting. The purpose of the project is to create a ""junior developer"" agent that scaffolds an entire codebase based on a product spec provided by the user. The agent uses AI to generate code, which the user can modify and debug manually. The project aims to provide a human-centric and coherent whole program synthesis workflow.",90,4
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png","The .env file in the smol-ai/developer repository contains API keys for Modal and Anthropics, which are used in the code. It is created by copying over the .example.env file and filling in the necessary keys. The codebase is a prototype for a ""junior developer"" agent that scaffolds a codebase based on a product spec provided by the user. The codebase is simple, safe, and less than 200 lines of Python and Prompts. The project uses Modal as a self-provisioning runtime and requires access to the GPT-4 and Anthropics APIs, which are currently in private beta. The project can be run without Modal by following the instructions in the repository.",90,5
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal.com, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy over the .example.env file and fill in the API keys before running the project. The project does not have any Python dependencies to manage thanks to the use of Modal as a self-provisioning runtime. The project is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for the user once they provide a product spec. The AI-enabled workflow is human-centric and allows for easy customization. The project is easy to understand and can be adapted on a fork for use on other infrastructures.",90,6
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal.com, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy over the .example.env file and fill in the API keys to use the project. The project can be run without Modal by following the instructions in the install section of the documentation. The .env file is not relevant to the purpose of the project, which is to create a ""junior developer"" agent that scaffolds an entire codebase based on a product spec.",90,7
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal, GPT-4, and Anthropocene Claude 100k Context API. It is necessary to copy over the .example.env file and fill in the API keys to use the project. The project does not have any Python dependencies to manage thanks to the use of Modal as a self-provisioning runtime. The project is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for the user once they give it a product spec. The AI is only used as long as it is adding value, and the user can take over the codebase from the ""smol dev"" with no fuss and no hurt feelings.",90,8
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png","The .env file in the smol-ai/developer repository contains API keys for Modal and Anthropics, which are used in the code. It is created by copying over the .example.env file and filling in the necessary keys. The codebase is designed to be simple and customizable, with a focus on human-centric and coherent whole program synthesis. The project uses AI to scaffold an entire codebase based on a product spec provided by the user. The generated code can be modified by the user as needed, with the help of a debugger tool. The project is still in development and requires access to private beta APIs for Modal and GPT-4.",80,9
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx","The .env file in the smol-ai/developer repository is used to store API keys for Modal, GPT-4, and Anthropoc Claude 100k Context API. It is necessary to copy over the .example.env file and fill in the API keys to use the project. The project does not have any Python dependencies to manage thanks to using Modal as a self-provisioning runtime. The project is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The AI is only used as long as it is adding value, and once it gets in your way, you can take over the codebase from your smol junior developer with no fuss and no hurt feelings.",90,10
What is the point of the .env file?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,.env
__pycache__
.vscode
# Ignore everything in the generated directory
/generated/*

# Don't ignore .png files in the generated directory
!/generated/*.png","The .env file in the smol-ai/developer repository contains API keys for Modal and Anthropics, which are used in the code. It is created by copying over the .example.env file and filling in the necessary keys. The codebase is a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. The project uses Modal as a self-provisioning runtime and requires access to the GPT-4 and Anthropics APIs, which are currently in private beta. The codebase is simple, safe, and less than 200 lines of Python and Prompts. The AI is used to add value until it gets in the way, at which point the human can take over the codebase.",90,11
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken","To efficiently and effectively create a website using the smol-ai/developer repository, a junior developer can leverage the ""smol dev"" agent that scaffolds an entire codebase based on a product spec. This prototype AI-enabled workflow is human-centric and allows for customization and understanding with a codebase of less than 200 lines of Python and Prompts. The developer can write a basic prompt for the app they want to build, generate code with main.py, run/read the code, and add to the prompt as they discover underspecified parts. The AI is only used as long as it adds value, and the developer can take over the codebase from the ""smol dev"" with no fuss. The project requires Modal.com, GPT-4 API, and anthropic claude 100k context API, which are currently in private beta. The developer can adapt the code on a fork and open issues/PRs. The project also has the ability to install its own dependencies, self-heal by running the code itself, and make agents that autonomously run the code in a loop.",70,0
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for a website based on a product spec. It is a human-centric and coherent whole program synthesis tool that uses prompts to generate code. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The tool is AI-enabled but still firmly human developer-centric, and the AI is only used as long as it adds value. The tool is not a no-code or low-code tool but a higher order evolution of programming where you still need to be technical but no longer have to implement every detail to scaffold things out. The tool requires Modal.com, GPT-4 API, and anthropic claude 100k context API, which are private beta tools. The repository also contains a Chrome Manifest V3 extension that reads the current page and offers a popup UI that has the page title+content and a textarea for a prompt. The extension was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process. The tool can be used by running main.py with a prompt.",80,1
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for a website once given a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The AI is only used as long as it adds value, and the human developer can take over the codebase from smol dev at any time. The repository also includes a video demo and a Chrome extension example. To use smol dev, clone the repository and copy over the .example.env file to .env, filling in your API keys. There are no Python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses three waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The most important skill in being an AI engineer is social engineering to get off waitlists.",90,2
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken","To efficiently and effectively create a website using the smol-ai/developer repository, a junior developer can leverage the ""smol dev"" agent that scaffolds an entire codebase based on a product spec. This prototype AI-enabled workflow is human-centric and allows for customization and understanding with less than 200 lines of Python and Prompts. The developer can write a basic prompt for the app they want to build, generate code with main.py, run/read the code, and add to the prompt as they discover underspecified parts. The AI is only used as long as it adds value, and the developer can take over the codebase from the ""smol dev"" at any time. The repository requires Modal.com, GPT-4 API, and anthropic claude 100k context API, which are currently in private beta. The developer can adapt the code on a fork and open issues/PRs. The repository also discusses potential challenges such as dependency management and self-healing.",80,3
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called `smol dev` that can scaffold an entire codebase for a website based on a product spec. This agent is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and less than 200 lines of Python and Prompts. The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer-centric, workflow. The repository also contains a Chrome extension example that reads the current page and generates a response from OpenAI based on a prompt. To use the `smol dev` agent, clone the repository and copy over `.example.env` to `.env` filling in your API keys. There are no Python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, this project also uses three waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. You can run this project without Modal by following the instructions in the repository.",90,4
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for a website once given a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The AI is only used as long as it adds value, and the human developer can take over the codebase from the smol junior developer at any time. The repository also includes a video demo and an arch diagram. To install, clone the repository and copy over `.example.env` to `.env`, filling in your API keys. The project uses Modal.com, GPT-4 API, and anthropic claude 100k context API, all of which are private beta. The repository also includes a Chrome extension example that was generated by the prompt in `prompt.md`. To use smol dev, run `modal run main.py --prompt ""your prompt""` or extract your prompt to a file and run `modal run main.py --prompt prompt.md`.",80,5
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","Yes, a junior developer can use the code and tools in the smol-ai/developer repository to build a website from scratch. The repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The AI is only used as long as it is adding value, and the user can take over the codebase from the junior developer at any time. The repository also includes a video demo and installation instructions.",90,6
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for a website based on a product spec. It is a human-centric and coherent whole program synthesis tool that uses prompts to generate code. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The tool is AI-enabled but still firmly human developer-centric, and the AI is only used as long as it adds value. The tool does not have any specific dependencies, and it can be used with or without Modal.com. The repository also contains a Chrome extension example that was generated using the prompt in prompt.md. To use smol dev, one needs to clone the repository and run main.py with a prompt.",90,7
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for a website based on a product spec. This AI-enabled workflow is human-centric and allows for customization. The codebase is simple, safe, and less than 200 lines of Python and Prompts. The repository also includes a Chrome extension example that was generated using the prompt in prompt.md. To use smol dev, clone the repository and copy over .example.env to .env, filling in API keys. There are no Python dependencies to manage thanks to using Modal as a self-provisioning runtime. However, the project uses three waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The example Chrome extension can be loaded in Chrome by going to Manage Extensions and loading the relevant folder. To use smol dev, run main.py with the desired prompt.",90,8
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,modal-client
openai
tiktoken,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","Yes, a junior developer with limited experience can use the smol-ai/developer repository to build a website. The repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The AI is helpful, harmless, and honest, and the codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow. The user can simply add to the prompt as they discover underspecified parts of the prompt, manually run the code and identify errors, and paste the error into the prompt just like they would file a github issue. Loop until happiness is attained.",100,9
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken","The smol-ai/developer repository contains a prototype of a ""junior developer"" agent that can scaffold an entire codebase for a website based on a product spec. The agent is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and smol. The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow. The agent can be installed by cloning the repository and copying over `.example.env` to `.env` filling in your API keys. However, the project uses some private beta APIs, so you may need to adapt the code on a fork if you want to use it on other infra.",90,10
Can my junior dev create a website?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","Yes, the smol-ai/developer repository contains a prototype of a ""junior developer"" agent called smol dev that can scaffold an entire codebase for you based on a product spec. This agent is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. The smol dev agent uses AI to generate code based on a prompt, which can be iteratively refined by the human developer until they are satisfied with the result. The generated code can be manually run and errors can be identified and fixed by the human developer, or they can use the debugger.py tool to make specific code change suggestions. The smol dev agent is not a no-code or low-code solution, but rather a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail to scaffold things out. To use the smol dev agent, you can clone the repository and follow the installation instructions provided in the README file.",100,11
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human if it gets in the way. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no Python dependencies to wrangle. The example Chrome extension in the repository was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process.",90,0
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human at any time. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no python dependencies to wrangle.",90,1
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human at any time. The project uses Modal as a self-provisioning runtime and requires no python dependencies. The example Chrome extension was generated by the prompt in prompt.md and can be tried by loading it into Chrome.",90,2
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human if it gets in the way. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no Python dependencies to wrangle.",90,3
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human at any time. The smol-dev agent is designed to be helpful, harmless, and honest, and the codebase is simple, safe, and less than 200 lines of Python and Prompts. The project uses Markdown for prompts and GPT-4 API for whole program synthesis. The example Chrome extension in the repository was generated entirely by the prompt in prompt.md, and was built up over time by adding more words to the prompt in an iterative process.",80,4
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human at any time. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no python dependencies to wrangle.",90,5
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human if it gets in the way. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no python dependencies to wrangle. The example Chrome extension was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process.",80,6
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves writing a basic prompt for the desired application in prompt.md, running main.py to generate code, manually running and identifying errors in the code, and pasting the error into the prompt for further refinement. The debugger.py tool can also be used for specific code change suggestions. The AI is only used as long as it adds value, and can be taken over by the user at any time. The project uses Modal as a self-provisioning runtime and requires no python dependencies. The example Chrome extension was generated using a prompt in prompt.md and can be tested by loading the unpacked folder in Chrome. The smol dev tool can be used to extract prompts to a file and ensure coherence between files using shared_dependencies.md.",80,7
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves writing a basic prompt for the desired application in prompt.md, running main.py to generate code, manually running and identifying errors in the code, and pasting the error into the prompt for further development. The AI is only used as long as it adds value, and can be taken over by the user at any time. The codebase is simple, safe, and less than 200 lines of Python and Prompts. The project uses Modal as a self-provisioning runtime and requires no Python dependencies. The example Chrome extension was generated by the prompt in prompt.md and can be tried by loading the relevant folder in Chrome. The smol dev can be used by running main.py with a prompt in the command line.",80,8
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The smol dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no python dependencies to wrangle. The example Chrome extension was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process.",80,9
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human at any time. The smol-dev agent is designed to be helpful, harmless, and honest, and the codebase is simple, safe, and less than 200 lines of Python and Prompts. The project uses Markdown for prompts and GPT-4 API for whole program synthesis. The example Chrome extension in the repository was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process.",80,10
What is the high level workflow starting with main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","The high level workflow starting with main.py in the smol-ai/developer repository involves a human writing a basic prompt for the app they want to build, which is then used by main.py to generate code. The human can then manually run and read the code, add to the prompt as they discover underspecified parts of it, paste errors into the prompt, and use debugger.py for specific code change suggestions. This loop continues until the desired outcome is achieved. The AI is only used as long as it adds value, and can be taken over by the human if it gets in the way. The smol-dev agent is a prototype of a ""junior developer"" that scaffolds an entire codebase out for the user once they give it a product spec. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize. The project uses Modal as a self-provisioning runtime and requires no python dependencies to wrangle. The example Chrome extension was generated by the prompt in prompt.md and was built up over time by adding more words to the prompt in an iterative process.",80,11
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository. `code2prompt` generates prompts for whole program synthesis using Markdown, while `code2prompt2code` produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The latter script required a few iterations to get right. The former script has several potential future directions, including specifying `.md` files for each generated file, bootstrapping the prompt for existing codebases, and installing its own dependencies. The repository also contains a `smol debugger` and `smol pm` for debugging and synthesizing the whole program, respectively. The goal of these tools is to provide a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.",90,0
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository that generate code based on prompts. `code2prompt` generates a prompt based on existing code, while `code2prompt2code` generates a semi-working Chrome extension based purely on a model-generated description of a different codebase. The repository contains documentation on how to use these scripts, as well as future directions for the project.",90,1
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository. `code2prompt` generates prompts for whole program synthesis using Markdown, while `code2prompt2code` produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The latter script required a few iterations to get right. The former script has potential future directions, such as specifying `.md` files for each generated file and bootstrapping the prompt for existing codebases. Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix English and code. The scripts also have a `smol debugger` and `smol pm` for debugging and synthesizing the whole program, respectively. The goal of these scripts is to provide a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.",90,2
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","The main difference between code2prompt and code2prompt2code is that the former generates a prompt for a codebase while the latter produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The repository contains various scripts and tools for whole program synthesis using GPT-4, which can generate prompts for different files in a codebase. The generated prompts can be fine-tuned to produce better results. The repository also includes a debugger tool that can read the entire codebase to make specific code change suggestions. The goal of the repository is to provide a higher order evolution of programming where developers still need to be technical but no longer have to implement every detail to scaffold things out.",80,3
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","The main difference between code2prompt and code2prompt2code is that the former generates a prompt for a codebase while the latter produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The repository contains various tools and scripts that use GPT-4 to prompt for whole program synthesis using Markdown. The prompts can be fine-tuned for each generated file, and the program can understand how to code around a new API by pasting in the `curl` input and output. The generated codebase can be debugged using the `smol debugger` tool, which takes advantage of longer context to provide specific fix suggestions. The `smol pm` tool can synthesize the whole program from the generated directory in context. The repository aims to provide a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail to scaffold things out.",80,4
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository that generate code based on prompts. The former generates a Chrome extension based on a model-generated description of a different codebase, while the latter generates a vertically resizable form with text areas for user and style prompts. The repository contains documentation on how to use these scripts, as well as future directions for the project.",90,5
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository. `code2prompt` generates prompts for whole program synthesis using Markdown, while `code2prompt2code` produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The latter script required a few iterations to get right. The former script has potential future directions, such as specifying `.md` files for each generated file and bootstrapping the prompt for existing codebases. Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix English and code. The scripts also have a `smol debugger` and `smol pm` for debugging and synthesizing the whole program, respectively. The goal of these scripts is to provide a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.",90,6
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository that generate code based on prompts. `code2prompt` generates a prompt based on an existing codebase, while `code2prompt2code` generates a semi-working Chrome extension based purely on a model-generated description of a different codebase. The repository contains documentation on how to use these scripts, as well as future directions for the project.",90,7
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository that generate code based on prompts. The former generates a Chrome extension based on a model-generated description of a different codebase, while the latter generates a vertically resizable form with text areas for user input. The repository contains documentation on how to use these scripts and future directions for their development.",90,8
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","The main difference between code2prompt and code2prompt2code in the smol-ai/developer repository is that code2prompt generates a descriptive prompt for a codebase, while code2prompt2code produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The repository contains various scripts and tools for whole program synthesis, including the ability to specify .md files for each generated file, bootstrap the prompt for existing codebases, and install its own dependencies. Markdown is used as the perfect way to prompt for whole program synthesis because it is easy to mix English and code. The repository also includes a smol debugger and smol pm for debugging and synthesizing the whole program, respectively. The goal of the repository is to provide a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.",80,9
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","The main difference between code2prompt and code2prompt2code is that the former generates a prompt for a given codebase while the latter produces a semi-working Chrome extension copy based purely on the model-generated description of a different codebase. The repository contains various scripts and tools for whole program synthesis using GPT-4, which can be used to prompt for code generation and debugging. The prompts can be specified in Markdown format and can include code samples. The generated code can have cross-dependencies, which can be resolved by specifying a shared dependencies file or a specific name in the prompt. The generated code can be debugged using the smol debugger, which takes advantage of longer context to provide specific fix suggestions. The smol pm tool can synthesize the whole program from the generated directory in context. The AI is used as long as it adds value, and the codebase can be taken over from the smol junior developer when necessary. This approach represents a higher order evolution of programming that combines technical expertise with AI-generated prompts and code.",80,10
WHats the difference between code2prompt and code2prompt2code?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- at the bottom of the popup, show a vertically resizable form that has:
      - a 2 line textarea with an id and label of `userPrompt`
        - `userPrompt` has a default value of
            ```js
            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;
            ```js
      - a 4 line textarea with an id and label of `stylePrompt`
        - `stylePrompt` has a default value of
            ```js
            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:
            
            <h1>{title here}</h1>
            <h3>{section title here}</h3>
            <details>
              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>
              <ul>
                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>
                <li><strong>{second point}</strong>: {same as above}</li>
                <li><strong>{third point}</strong>: {same as above}</li>
                <!-- a fourth point if warranted -->
              </ul>
            </details>
            <h3>{second section here}</h3>
            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>
            <details>,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","`code2prompt` and `code2prompt2code` are both scripts in the `smol-ai/developer` repository that generate code based on prompts. `code2prompt` generates a prompt based on an existing codebase, while `code2prompt2code` generates a semi-working Chrome extension based purely on a model-generated description of a different codebase. The repository contains documentation on how to use these scripts, as well as future directions for the project.",90,11
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The extension lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. When clicked, the extension pops up a small window with a simple, modern, slick, minimalistic styled HTML popup. It checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it. It accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. It renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content. At the bottom of the popup, it shows a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. It has to run in a browser environment, so no Nodejs APIs allowed.",80,0
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The extension lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. When clicked, the extension pops up a small window with a simple, modern, slick, minimalistic styled HTML popup. It checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it. It accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. It renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content. At the bottom of the popup, it shows a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. It disables these inputs while it waits. It has to run in a browser environment, so no Nodejs APIs are allowed.",80,1
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI to send the page content to the Anthropic Claude API along with a prompt to summarize it. The popup also allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. When clicked, the extension pops up a small window with a simple, modern, slick, minimalistic styled HTML popup. It then accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is then rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. It is important to note that it has to run in a browser environment, so no Nodejs APIs are allowed.",80,2
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The return signature of the Anthropomorphic API is provided.",80,3
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup also allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, the extension calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension uses the `claude-instant-v1` model if `pageContent` is <70k words or the `claude-instant-v1-100k` model if more. The extension requests max tokens = the higher of (25% of the length of the page content, or 750 words).",80,4
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet-pointed, easy-to-read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension uses the `claude-instant-v1` model if `pageContent` is <70k words or the `claude-instant-v1-100k` model if more. The extension requests max tokens = the higher of (25% of the length of the page content, or 750 words).",50,5
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet-pointed, easy-to-read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension uses the `claude-instant-v1` model if `pageContent` is <70k words or the `claude-instant-v1-100k` model if more. It requests max tokens = the higher of (25% of the length of the page content, or 750 words).",70,6
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup also allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, the extension calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension disables these inputs while it waits.",80,7
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI to send the page content to the Anthropic Claude API along with a prompt to summarize it. The popup allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, the extension calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension disables these inputs while it waits.",80,8
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup allows the user to modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, the extension calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension disables these inputs while it waits.",80,9
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it. The popup lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. The extension runs in a browser environment, so no Nodejs APIs are allowed. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The Anthropic-generated HTML summary is rendered inside of the popup in a div with an id of content. At the bottom of the popup, there is a textbox with an id of `userPrompt` and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension uses the `claude-instant-v1` model if `pageContent` is <70k words or the `claude-instant-v1-100k` model if more. The extension requests max tokens = the higher of (25% of the length of the page content, or 750 words).",80,10
How do I use Claude here?,https://github.com/smol-ai/developer,"a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.

When clicked:
- pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - checks its own storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
  - which accesses the title and main content of the currently open page (extracted via an injected content script, and sent over using a 'pageContent' action) and renders it inside a <details> tag with a ""Full article"" <summary> at the top (tastefully styled).
  - from the popup script, calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved.
  - renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content
  - at the bottom of the popup, show a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. disable these inputs while it waits.

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.,a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that sends the page content to the Anthropic Claude API along with a prompt to summarize it, and lets the user modify that prompt and re-send the prompt+content to get another summary view of the content.


- When clicked:
  - it injects a content script `content_script.js` on the currently open tab, 
  and accesses the title `pageTitle` and main content `pageContent` of the currently open page 
  (extracted via an injected content script, and sent over using a `storePageContent` action) 
  - in the background, receives the `storePageContent` data and stores it
  - pops up a small window with a simple, modern, slick, minimalistic styled html popup
  - in the popup script
    - retrieves the page content data using a `getPageContent` action (and the background listens for the `getPageContent` action and retrieves that data) 
    - check extension storage for an `apiKey`, and if it isn't stored, asks for an API key to Anthropic Claude and stores it.
    - calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1-100k` model with: 
      - append the page title
      - append the page content
      - append a prompt to ask for a detailed, easy to read HTML summary of the given content with 3-4 highlights per section with important keywords bolded and important links preserved.
        in this format:
        ```js
        defaultPrompt = `Human: Please provide a detailed, easy to read HTML summary of the given content,<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Anthropic Claude Summary Extension</title>
    <link rel=""stylesheet"" href=""styles.css"">
</head>
<body>
    <form>
        <label for=""userPrompt"">User Prompt:</label>
        <textarea id=""userPrompt""></textarea>
        <label for=""stylePrompt"">Style Prompt:</label>
        <textarea id=""stylePrompt""></textarea>
        <label for=""maxTokens"">Max Tokens:</label>
        <input type=""number"" id=""maxTokens"">
        <button type=""button"" id=""sendButton"">Request Summary</button>
    </form>
    <div id=""content""></div>
    <div id=""loadingIndicator"" style=""display:none;""></div>
    <script src=""popup.js""></script>
</body>
</html>,```
        - and use the `claude-instant-v1` model (if `pageContent` is <70k words) or the `claude-instant-v1-100k` model (if more) 
        - requesting max tokens = the higher of (25% of the length of the page content, or 750 words)
        - if another submit event is hit while the previous api call is still inflight, cancel that and start the new one
    - renders the Anthropic-generated result at the top of the popup in a div with an id of `content`

Important Details:

- It has to run in a browser environment, so no Nodejs APIs allowed.

- the return signature of the anthropic api is curl https://api.anthropic.com/v1/complete\
  -H ""x-api-key: $API_KEY""\
  -H 'content-type: application/json'\
  -d '{
    ""prompt"": ""\n\nHuman: Tell me a haiku about trees\n\nAssistant: "",
    ""model"": ""claude-v1"", ""max_tokens_to_sample"": 1000, ""stop_sequences"": [""\n\nHuman:""]
  }'
{""completion"":"" Here is a haiku about trees:\n\nSilent sentinels, \nStanding solemn in the woods,\nBranches reaching sky."",""stop"":""\n\nHuman:"",""stop_reason"":""stop_sequence"",""truncated"":false,""log_id"":""f5d95cf326a4ac39ee36a35f434a59d5"",""model"":""claude-v1"",""exception"":null},userPrompt.disabled = true;
      sendButton.disabled = true;

      fetch('https://api.anthropic.com/v1/complete', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'content-type': 'application/json',
        },
        body: JSON.stringify({
          prompt: fullPrompt,
          model: 'claude-instant-v1-100k',
          max_tokens_to_sample: 1000,
          stop_sequences: ['\n\nHuman:'],
        }),
      })
        .then((res) => {
          if (res.status === 401) {
            chrome.storage.local.remove(['apiKey']);
            throw new Error('Invalid API key');
          }
          return res.json();
        })
        .then((data) => {
          content.innerHTML = data.completion;
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        })
        .catch((error) => {
          console.error(error);
          loadingIndicator.style.display = 'none';
          userPrompt.disabled = false;
          sendButton.disabled = false;
        });
    });
  }

  chrome.storage.local.get(['apiKey'], (result) => {
    if (!result.apiKey) {
      const apiKey = prompt('Please enter your Anthropic Claude API key:');
      chrome.storage.local.set({ apiKey }, () => {
        requestAnthropicSummary(defaultPrompt, apiKey);
      });
    } else {","To use Claude in the given Github repository, you can use a Chrome Manifest V3 extension that reads the current page and offers a popup UI to send the page content to the Anthropic Claude API along with a prompt to summarize it. The extension lets the user modify the prompt and re-send the prompt+content to get another summary view of the content. When clicked, the extension pops up a small window with a simple, modern, slick, minimalistic styled HTML popup. It checks its own storage for an apiKey, and if it isn't stored, asks for an API key to Anthropic Claude and stores it. The extension accesses the title and main content of the currently open page and renders it inside a <details> tag with a ""Full article"" <summary> at the top. From the popup script, it calls the Anthropic model endpoint https://api.anthropic.com/v1/complete with the `claude-instant-v1` model with the page content, prompting it to ask for a detailed, bullet pointed, easy to read HTML summary of the given content with important keywords bolded and important images and links preserved. The extension renders the Anthropic-generated HTML summary inside of the popup in a div with an id of content. At the bottom of the popup, it shows a textbox with an id of `userPrompt` a default value of the same prompt that we used, and a submit button with an id of `sendButton` that lets the user re-ask Anthropic with the same content but different prompt. The extension has to run in a browser environment, so no Nodejs APIs are allowed.",80,11
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To recreate the idea presented in the smol-ai/developer repository using Python code, you can follow the instructions in the ""install"" section of the repository. The codebase uses Modal as a self-provisioning runtime and requires API keys for Modal.com, GPT-4, and anthropic claude 100k context. The repository also suggests using a web container or dockerizing to avoid dependency issues. The ""smol developer"" agent in the repository scaffolds an entire codebase based on a product spec provided in a prompt. The codebase is simple, safe, and less than 200 lines of Python and Prompts. Future directions for the repository include specifying .md files for each generated file and the ability to install its own dependencies.",50,0
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The smol-ai/developer repository presents a prototype for a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, making it easy to understand and customize. The workflow involves writing a basic prompt for the app you want to build, generating code using `main.py`, and then running/reading the code. The code can be modified by adding to the prompt as you discover underspecified parts of the prompt. The repository suggests using Markdown as the perfect way to prompt for whole program synthesis because it is easy to mix English and code. The codebase can self-heal by running the code itself and using errors as information for reprompting. The repository also suggests using anthropic as the coding layer and generating functions that speak modal to solve the dependency thing. The repository provides a video demo and an arch diagram for reference. To install, clone the repository and copy over `.example.env` to `.env` filling in your API keys. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The repository suggests adapting the code on a fork if you want to use it on other infra.",50,1
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","Based on the information provided in the repository, it appears that the goal of the ""smol developer"" project is to create a human-centric and coherent whole program synthesis tool that can scaffold an entire codebase based on a product spec. The tool uses AI to generate code based on prompts provided by the user, and the user can manually run the code and identify errors, which can then be pasted back into the prompt for further refinement. The tool is designed to be easy to understand and customize, with a codebase of less than 200 lines of Python and prompts. To use the tool, the user would need to clone the repository and fill in their API keys. There are no Python dependencies to worry about, thanks to the use of Modal as a self-provisioning runtime. However, the project does use several private beta APIs, including Modal.com, GPT-4, and Anthropoc Claude 100k context API. The project also includes a Chrome extension example. Future directions for the project include specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and making the tool able to install its own dependencies.",0,2
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","The repository ""smol-ai/developer"" contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The code is written in Python and Prompts, and is easy to understand and customize. The AI-enabled workflow involves writing a basic prompt for the app, generating code using ""main.py"", and then running/reading the code. The user can add to the prompt as they discover underspecified parts of the prompt. The codebase is <200 lines of code and the project uses Modal as a self-provisioning runtime. The project also uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The user can adapt the code on a fork if they want to use it on other infra. Future directions include specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and making agents that autonomously run the code in a loop/watch the prompt file and regenerate code each time, on a new git branch.",70,3
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","The repository ""smol-ai/developer"" contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The code is written in Python and Prompts, and is easy to understand and customize. The AI-enabled workflow involves writing a basic prompt for the app you want to build, generating code using ""main.py"", and then running/reading the code. The generated code can be further refined by adding prompts for each generated file. The codebase is designed to be helpful, harmless, and honest, and is complemented by a codebase that is simple, safe, and smol. The repository also contains a video demo and an architecture diagram. To use the code, you need to clone the repository and copy over "".example.env"" to "".env"" filling in your API keys. There are no Python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The most important skill in being an AI engineer is social engineering to get off waitlists. The repository also lists some future directions for the project, such as specifying .md files for each generated file, bootstrapping the ""prompt.md"" for existing codebases, and making agents that autonomously run the code in a loop/watch the prompt file and regenerate code each time, on a new git branch.",70,4
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","The ""smol developer"" repository provides a prototype for a ""junior developer"" agent that scaffolds an entire codebase based on a product spec. The code is generated using a prompt-based workflow that involves human input and AI assistance. The codebase is designed to be simple, safe, and under 200 lines of Python and Prompts. The repository provides instructions for installation and usage, including the ability to install dependencies and self-heal by using errors as information for reprompting. Future directions for the project include specifying .md files for each generated file and the ability to bootstrap the prompt.md for existing codebases.",50,5
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","The repository ""smol-ai/developer"" contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The code is written in Python and uses AI to generate code based on prompts. The generated code can be manually reviewed and modified. The repository provides a video demo and an architecture diagram. To use the code, you need to clone the repository and fill in your API keys. The project uses Modal as a self-provisioning runtime and requires access to GPT-4 API and anthropic claude 100k context API, both of which are in private beta. The repository also lists some future directions for the project, such as specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and making agents that autonomously run the code in a loop.",80,6
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","The repository ""smol-ai/developer"" contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The code is written in Python and Prompts, and is easy to understand and customize. The AI-enabled workflow involves writing a basic prompt for the app you want to build, generating code using ""main.py"", and then running/reading the code. The generated code can be finetuned using further prompts. The codebase is <200 lines of Python and Prompts. The repository also contains a video demo and an arch diagram. To install, you need to clone the repository and copy over "".example.env"" to "".env"" filling in your API keys. There are no Python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The most important skill in being an AI engineer is social engineering to get off waitlists. The repository also lists some future directions for the project.",90,7
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","Based on the information provided in the repository, it appears that the goal of the ""smol developer"" project is to create a tool that can generate code based on a prompt provided by the user. The code is generated using AI and can be manually edited by the user as needed. The project does not require any Python dependencies and can be run using Modal as a self-provisioning runtime. However, it does require access to private beta APIs for Modal, GPT-4, and anthropic claude 100k context. The project is designed to be human-centric and easy to understand and customize. It is not a low-code or no-code solution, but rather a third option that still requires technical knowledge. To implement the idea presented in the repository, one would need to clone the repository and follow the installation instructions provided. Once installed, the user can provide a prompt and generate code using the main.py file. The generated code can then be manually edited as needed. Future directions for the project include specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and making the tool able to install its own dependencies.",80,8
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To recreate the concept presented in the smol-ai/developer repository using Python code, you can clone the repository and fill in your API keys in the .env file. There are no Python dependencies to worry about thanks to the use of Modal as a self-provisioning runtime. However, the project does use some private beta APIs, so you may need to get on a waitlist or use alternatives. The smol developer agent is a prototype for scaffolding an entire codebase based on a product spec, using prompts to generate code. The codebase is simple, safe, and less than 200 lines of Python and Prompts. To improve the agent, future directions include specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and enabling the agent to install its own dependencies.",50,9
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","The repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The code is written in Python and Prompts, and is easy to understand and customize. The AI-enabled workflow involves writing a basic prompt for the app, generating code, running/reading the code, and adding to the prompt as needed. The codebase is simple, safe, and less than 200 lines of code. The repository does not provide Python code that implements the concept described, but it does provide instructions on how to install and run the code. The codebase does not have any Python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. The repository also discusses future directions for the project, such as specifying .md files for each generated file and the ability to install its own dependencies.",50,10
Give me basic python code to recreate this idea.,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","The ""smol developer"" repository proposes a human-centric approach to program synthesis using prompts and AI. The codebase is small and easy to understand, with prompts written in Markdown. The AI generates code based on the prompts and the user can add to the prompts as needed. The code can be debugged by pasting error messages into the prompt and using the ""debugger.py"" tool. The repository suggests using Python and provides instructions for installation. However, the repository relies on private beta APIs and services, so adaptation may be necessary. Overall, the ""smol developer"" approach offers a promising way to scaffold codebases quickly and efficiently. Code examples are available in the repository.",80,11
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize.",80,0
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. To install, simply clone the repository and copy over `.example.env` to `.env` filling in your API keys.",80,1
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. To install, simply clone the repository and copy over `.example.env` to `.env` filling in your API keys.",80,2
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. To install the repository, simply clone it and copy over `.example.env` to `.env`, filling in your API keys. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project also uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. You can run the project without Modal by following the instructions in the repository.",80,3
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run the code and identify errors. If you make a tweak to the prompt and only want it to affect one file, you can specify the file parameter. The codebase is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize.",80,4
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The repository also includes a demo example in `prompt.md` that shows the potential of AI-enabled, human-centric workflow. Loop until happiness is attained, and if you make a tweak to the prompt and only want it to affect one file, specify the file parameter. To install, simply clone the repository and copy over `.example.env` to `.env` filling in your API keys. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project also uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. You can run the project without Modal by following the instructions in the repository.",80,5
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize.",80,6
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The repository uses Modal as a self-provisioning runtime, so there are no Python dependencies to wrangle. However, the project also uses three waitlisted things: Modal.com, GPT-4 API, and Anthropoc Claude 100k context API. You can adapt the code on a fork if you want to use it on other infra.",80,7
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize.",80,8
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need for embedding of the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize.",80,9
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can feed in an error and get a response, taking advantage of longer context so there is no need to embed the source. Additionally, you can use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. The `smol dev` agent scaffolds an entire codebase out for you once you give it a product spec, and you can manually run and identify errors, or paste the error into the prompt just like filing a Github issue. Loop until happiness is attained. The codebase is simple, safe, and smol, making it easy to understand and customize. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. You can adapt the code on a fork if you want to use it on other infra.",80,10
How do I use the debugger?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension","To effectively use the debugger in the smol-ai/developer repository, you can use the `debugger.py` script which reads the entire codebase to make specific code change suggestions. You can also use the `code2prompt.py` script to get a prompt back that could synthesize the whole program. Additionally, you can specify the file parameter if you want to make a tweak to the prompt and only affect one file. To install the repository, clone it and copy over `.example.env` to `.env` filling in your API keys. There are no python dependencies to wrangle thanks to using Modal as a self-provisioning runtime. However, the project also uses 3 waitlisted things: Modal.com, GPT-4 API, and anthropic claude 100k context API. You can run the project without Modal by following the instructions in the documents.",80,11
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include avoiding dependency issues by dockerizing or using a web container, implementing self-healing by running the code itself and using errors for reprompting, and making agents that autonomously run the code in a loop and regenerate code on new git branches. Additionally, manually running the code and identifying errors, pasting the error into the prompt, and using debugger.py for specific code change suggestions can be helpful. The smol developer prototype can also be used to scaffold an entire codebase out by developing a scaffolding prompt in a tight loop with the smol dev. Future directions for improvement include specifying .md files for each generated file and the ability to install its own dependencies.",70,0
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, it is suggested to dockerize or use a web container to avoid dependency issues. Another option is to use self-healing by running the code itself and using errors as information for reprompting. Additionally, agents can be created to autonomously run the code in a loop and regenerate code on a new git branch. To identify underspecified parts of the prompt, the code can be manually run and errors can be pasted into the prompt. The use of anthropic as the coding layer is also recommended. The repository uses Modal as a self-provisioning runtime, and there are no python dependencies to wrangle. However, it also uses 3 waitlisted things: Modal.com, GPT-4 api, and anthropic claude 100k context api. The example chrome extension can be tried by following the instructions in the repository. Future directions include specifying .md files for each generated file and bootstrapping the prompt.md for existing codebases.",50,1
How can I improve main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,if you make a tweak to the prompt and only want it to affect one file, and keep the rest of the files, specify the file param:

```bash
modal run main.py --prompt prompt.md  --file popup.js
```

## smol debugger

take the entire contents of the generated directory in context, feed in an error, get a response. this basically takes advantage of longer (32k-100k) context so we basically dont have to do any embedding of the source.

```bash
modal run debugger.py --prompt ""Uncaught (in promise) TypeError: Cannot destructure property 'pageTitle' of '(intermediate value)' as it is undefined.    at init (popup.js:59:11)""

# gpt4
modal run debugger.py --prompt ""your_error msg_here"" --model=gpt-4
```

## smol pm

take the entire contents of the generated directory in context, and get a prompt back that could synthesize the whole program. basically `smol dev`, in reverse.

```bash
modal run code2prompt.py # ~0.5 second

# use gpt4
modal run code2prompt.py --model=gpt-4 # 2 mins, MUCH better results
```

We have done indicative runs of both, stored in `code2prompt-gpt3.md` vs `code2prompt-gpt4.md`. Note how incredibly better gpt4 is at prompt engineering its future self.

Naturally, we had to try `code2prompt2code`...

```bash
# add prompt... this needed a few iterations to get right,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.","Recommended tools and techniques for debugging and testing changes to main.py in the smol-ai/developer repository include manually running the code and identifying errors, pasting the error into the prompt, and using debugger.py to make specific code change suggestions. The smol debugger can take advantage of longer context to respond to errors without embedding the source. Additionally, smol dev can scaffold an entire codebase based on a product spec provided in a prompt. The codebase is easy to understand and customize, and AI is only used as long as it adds value. The generated directory is deleted and all files are rewritten from scratch each time smol dev is run.",70,2
How can I improve main.py?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","There are several techniques and tools that can be used to improve the quality of main.py in the smol-ai/developer repository. These include using a debugger, self-healing by running the code and using errors as information for reprompting, using Markdown for whole program synthesis, copy and paste programming to understand unfamiliar APIs, and using tricks for whole program coherence. Additionally, there are future directions for the project, such as specifying .md files for each generated file and the ability to install its own dependencies.",50,3
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include avoiding dependency issues by dockerizing or using a web container, implementing self-healing by running the code itself and using errors for reprompting, and making agents that autonomously run the code in a loop and regenerate code on new git branches. Additionally, manually running the code and identifying errors, pasting the error into the prompt, and using debugger.py for specific code change suggestions can be helpful. The smol developer prototype can also be used to scaffold an entire codebase out by developing a scaffolding prompt in a tight loop with the smol dev. Future directions for improvement include specifying .md files for each generated file and the ability to install its own dependencies.",70,4
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include dockerizing or using a web container to avoid dependency issues, implementing self-healing by running the code itself and using errors as information for reprompting, and making agents that autonomously run the code in a loop and regenerate code each time on a new git branch. Additionally, manually running the code and identifying errors, pasting the error into the prompt, and using debugger.py for specific code change suggestions can be helpful. The smol dev agent can also scaffold an entire codebase out for you once you give it a product spec. It is important to note that AI should only be used as long as it is adding value and can be taken over by a human developer if it gets in the way.",70,5
How can I improve main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","There are a few potential pitfalls to be aware of when working with main.py in the smol-ai/developer repository. One issue is the potential for dependency madness when installing dependencies, which can be avoided by using a web container or generating functions that speak modal. Another potential issue is ensuring whole program coherence, particularly when dealing with indirect dependencies across files. This can be addressed by having GPT think through shared dependencies and specifying a specific name in the prompt. Additionally, it may be helpful to use Markdown for prompts and to paste error messages into the prompt for debugging. Finally, it's important to remember that the AI is only meant to be helpful and can be taken over by the human developer at any time.",70,6
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, there are several best practices to consider. One is to avoid dependency issues by dockerizing or using a web container. Another is to implement self-healing by running the code itself and using errors as information for reprompting. Additionally, using anthropic as the coding layer and making agents that autonomously run the code in a loop can be helpful. It is also recommended to add to the prompt as underspecified parts are discovered and to use debugger.py for specific code change suggestions. The smol developer agent can be used to scaffold an entire codebase out for you once you give it a product spec. Overall, the focus should be on a human-centric and coherent whole program synthesis approach.",50,7
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include dockerizing or using a web container to avoid dependency issues, implementing self-healing by running the code itself and using errors as information for reprompting, and making agents that autonomously run the code in a loop and regenerate code each time on a new git branch. Additionally, manually running the code and identifying errors, pasting the error into the prompt, and using debugger.py for specific code change suggestions can be helpful. The smol dev prototype can also be used to scaffold an entire codebase out by developing a scaffolding prompt in a tight loop with the smol dev. Future directions include specifying .md files for each generated file and the ability to install its own dependencies.",70,8
How can I improve main.py?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,### trying the example chrome extension

the `/generated` and `/exampleChromeExtension` folder contains `a Chrome Manifest V3 extension that reads the current page, and offers a popup UI that has the page title+content and a textarea for a prompt (with a default value we specify). When the user hits submit, it sends the page title+content to the Anthropic Claude API along with the up to date prompt to summarize it. The user can modify that prompt and re-send the prompt+content to get another summary view of the content.`

- go to Manage Extensions in Chrome
- load unpacked
- find the relevant folder in your file system and load it
- go to any content heavy site
- click the cute bird
- see it work

this entire extension was generated by the prompt in `prompt.md` (except for the images), and was built up over time by adding more words to the prompt in an iterative process.

## smol dev

basic usage

```bash
modal run main.py --prompt ""a Chrome extension that, when clicked, opens a small window with a page where you can enter a prompt for reading the currently open page and generating some response from openai""   
```

after a while of adding to your prompt, you can extract your prompt to a file, as long as your ""prompt"" ends in a .md extension we'll go look for that file

```bash
modal run main.py --prompt prompt.md   
```

each time you run this, the generated directory is deleted (except for images) and all files are rewritten from scratch. 

In the `shared_dependencies.md` file is a helper file that ensures coherence between files.,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include ensuring the ability to install its own dependencies, implementing self-healing by using errors as information for reprompting, and making agents that autonomously run the code in a loop and regenerate code on a new git branch. Additionally, it is important to use prompts for engineering rather than prompt engineering and to ensure coherence between files. The demo example in prompt.md shows the potential of AI-enabled, human-centric workflow where the human writes a basic prompt for the app they want to build, main.py generates code, and the human can add to the prompt as they discover underspecified parts of the prompt. The generated code can be manually run and errors can be pasted into the prompt just like filing a GitHub issue. The smol-dev agent is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for the user once they give it a product spec. It is easy to understand and customize with less than 200 lines of Python and Prompts.",70,9
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, some best practices include using a self-healing mechanism, making agents that autonomously run the code, and adding to the prompt as underspecified parts are discovered. It is also suggested to use anthropic as the coding layer and to dockerize or use a web container to avoid dependency issues. Additionally, it is recommended to specify .md files for each generated file and bootstrap the prompt.md for existing codebases. Overall, the goal is to create a human-centric and coherent whole program synthesis with a simple, safe, and smol codebase.",50,10
How can I improve main.py?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,## install

it's basically: 

- `git clone https://github.com/smol-ai/developer`.
- copy over `.example.env` to `.env` filling in your API keys.

There are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).

Unfortunately this project also uses 3 waitlisted things:

- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)
  - You can run this project w/o Modal following these instructions:
  - `pip install -r requirements.txt`
  - `python main_no_modal.py YOUR_PROMPT_HERE`
- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good
- (for the demo project) anthropic claude 100k context api (private beta)

> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword ""swyx""

you'll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i'll happily highlight your fork here.

### trying the example chrome extension,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","To improve the functionality of main.py in the smol-ai/developer repository, there are several best practices to consider. One is to avoid dependency issues by dockerizing or using a web container. Another is to implement self-healing by running the code itself and using errors as information for reprompting. Additionally, using anthropic as the coding layer and making agents that autonomously run the code in a loop can be helpful. It is also recommended to add to the prompt as underspecified parts are discovered and to use debugger.py for specific code change suggestions. The smol developer agent can be used to scaffold an entire codebase out for you once you give it a product spec. Finally, future directions include specifying .md files for each generated file and the ability to install its own dependencies.",70,11
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To improve the performance and scalability of the given repository, there are a few suggestions. Firstly, the ability to install its own dependencies should be improved to avoid dependency madness. This can be achieved by dockerizing or using a web container. Secondly, self-healing can be implemented by running the code itself and using errors as information for reprompting. However, this may be difficult in the chrome extension environment. Thirdly, using anthropic as the coding layer can be explored, but it may not work well. Fourthly, agents can be created to autonomously run the code in a loop and regenerate code each time on a new git branch. Lastly, errors can be added to the prompt as they are discovered and the code can be manually run and identified for errors. The AI is only used as long as it adds value. The repository is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is easy to understand and customize with less than 200 lines of Python and Prompts.",80,0
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,modal-client
openai
tiktoken,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To better integrate with other systems and technologies, architectural modifications could include containerization with Docker or Nix to avoid dependency issues. Additionally, self-healing capabilities could be implemented by running the code and using errors as information for reprompting. The use of anthropic as the coding layer is possible but may require further development. Another suggestion is to create agents that autonomously run the code and regenerate it on new git branches. The repository emphasizes a human-centric and coherent whole program synthesis approach, using prompts to generate code and allowing for manual adjustments as needed. The codebase is designed to be simple, safe, and small, with a focus on AI that is helpful, harmless, and honest.",85,1
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","To better support collaboration and ease of development in the smol-ai/developer repository, restructuring the architecture could involve using Markdown for whole program synthesis prompts, pasting in API input and output for the program to understand how to code around new APIs, and using `shared_dependencies.md` to ensure coherence across files. Additionally, the ability to install dependencies could be improved through containerization or generating functions that speak modal. Self-healing could be achieved by running the code and using errors as information for reprompting. The use of anthropic as the coding layer is possible but not yet fully functional. Making agents that autonomously run the code and regenerate it on new git branches could also be helpful. The repository's focus on a human-centric and coherent whole program synthesis approach, with a simple and customizable codebase, is key to its success.",80,2
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.","The current architecture of the code repository can be improved in several ways to enhance its usability and functionality. One approach is to dockerize or use Nix to avoid leaking dependencies into the execution environment. Another option is to use Modal to generate functions that speak modal and solve the dependency issue. Self-healing can also be implemented by running the code itself and using errors as information for reprompting. Anthropics can be used as the coding layer, but it doesn't work well in generating file code. Agents can be created to autonomously run the code in a loop and regenerate code on a new git branch. Additionally, the use of Markdown is recommended for prompting whole program synthesis, and copy and paste programming can be used to teach the program how to code around a new API. Debugging can be done by catting the whole codebase with the error message and getting specific fix suggestions. The codebase should be simple, safe, and smol, and engineering with prompts is recommended.",10,3
What architectural changes would make this better?,https://github.com/smol-ai/developer,"# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,modal-client
openai
tiktoken","To enhance the performance and functionality of the smol-ai/developer repository, there are a few potential improvements that could be made. One suggestion is to dockerize or use a web container to avoid dependency issues when installing dependencies. Another idea is to implement self-healing by running the code and using errors as information for reprompting. Additionally, there is potential to use anthropic as the coding layer, but this may require further development. Finally, creating agents that autonomously run the code in a loop and regenerate code on new git branches could be a useful feature. These suggestions could help improve the overall performance and functionality of the repository.",80,4
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To enhance the performance and scalability of the smol-ai/developer repository, there are a few potential solutions. One is to dockerize or use a web container to avoid dependency issues. Another is to implement self-healing by running the code and using errors as information for reprompting. Additionally, using anthropic as the coding layer may be helpful, although it currently has some limitations. Creating agents that autonomously run the code and regenerate it on new git branches could also be useful. Finally, developers can manually run the code, identify errors, and add to the prompt as needed. The goal is to create a human-centric and coherent whole program synthesis that is easy to understand and customize.",70,5
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,OPENAI_API_KEY=sk-xxxxxx
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxx,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To enhance the performance and scalability of the given repository, there are a few suggestions. Firstly, the ability to install its own dependencies should be improved to avoid dependency madness. This can be achieved by dockerizing or using a web container. Secondly, self-healing can be implemented by running the code itself and using errors as information for reprompting. However, this may be challenging in the chrome extension environment. Thirdly, using anthropic as the coding layer can be explored, but it may not generate file code very well. Fourthly, agents can be created to autonomously run the code in a loop and regenerate code each time on a new git branch. Lastly, errors can be identified by manually running the code and pasting the error into the prompt. The AI is only used as long as it adds value, and once it gets in the way, the codebase can be taken over by the developer. The repository is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. It is easy to understand and customize, with less than 200 lines of Python and Prompts.",80,6
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,MIT License Copyright (c) 2023 swyx

Permission is hereby granted, free of
charge, to any person obtaining a copy of this software and associated
documentation files (the ""Software""), to deal in the Software without
restriction, including without limitation the rights to use, copy, modify, merge,
publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the
following conditions:

The above copyright notice and this permission notice
(including the next paragraph) shall be included in all copies or substantial
portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF
ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO
EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.,modal-client
openai
tiktoken,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To enhance the functionality of the smol-ai/developer repository, there are a few potential improvements that could be made. One issue is the dependency management, which can be addressed through containerization or using a tool like Modal to generate functions that speak Modal. Another possibility is implementing self-healing by running the code itself and using errors as information for reprompting. Additionally, creating agents that autonomously run the code in a loop and regenerate code each time on a new git branch could be helpful. The codebase could also be improved by adding to the prompt as underspecified parts are discovered and using debugger.py for specific code change suggestions. The goal is to create a human-centric and coherent whole program synthesis that is easy to understand and customize.",70,7
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 15px;
}

textarea, input {
  display: block;
  width: 100%;
  margin-bottom: 10px;
  padding: 5px;
  font-size: 14px;
}

button {
  background-color: #4CAF50;
  border: none;
  color: white;
  padding: 10px 20px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 14px;
  margin: 10px 0;
  cursor: pointer;
}

button:hover {
  background-color: #45a049;
}

#content {
  margin-top: 20px;
  font-size: 14px;
  line-height: 1.5;
}

#loadingIndicator {
  display: none;
  font-size: 14px;
  color: #999;
},# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","To improve the performance of the code repository, some architectural changes can be made. One suggestion is to dockerize or use a web container to avoid dependency madness. Another idea is to implement self-healing by running the code itself and using errors as information for reprompting. Additionally, agents can be created to autonomously run the code in a loop and regenerate code each time on a new git branch. The use of Markdown for prompts and copy and paste programming can also be helpful. Debugging can be done by catting the whole codebase with the error message and getting specific fix suggestions. To ensure whole program coherence, an intermediate step can be added to ask GPT to think through shared dependencies. However, this is not perfect yet and specifying a specific name in the prompt can be a workaround.",50,8
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 15px;
}

textarea, input {
  display: block;
  width: 100%;
  margin-bottom: 10px;
  padding: 5px;
  font-size: 14px;
}

button {
  background-color: #4CAF50;
  border: none;
  color: white;
  padding: 10px 20px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 14px;
  margin: 10px 0;
  cursor: pointer;
}

button:hover {
  background-color: #45a049;
}

#content {
  margin-top: 20px;
  font-size: 14px;
  line-height: 1.5;
}

#loadingIndicator {
  display: none;
  font-size: 14px;
  color: #999;
},# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","To improve the performance of the code repository, some architectural changes can be made. One suggestion is to dockerize or use a web container to avoid dependency issues. Another idea is to implement self-healing by using errors as information for reprompting. Additionally, using anthropic as the coding layer can be explored. Making agents that autonomously run the code in a loop and regenerate code each time on a new git branch is another possibility. The use of Markdown for prompts and copy and paste programming can also be helpful. Debugging by catting the whole codebase with error messages and getting specific fix suggestions is a useful trick. Finally, to ensure whole program coherence, specifying shared dependencies and using clear communication can be effective.",70,9
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**","The current architecture of the code repository can be improved in several ways to support future development and growth. One approach is to use Markdown for whole program synthesis prompts, which allows for easy mixing of English and code. Additionally, the use of copy and paste programming can help the program understand how to code around new APIs. Debugging can be done by ""cat""ing the whole codebase with the error message and getting specific fix suggestions. Another suggestion is to specify .md files for each generated file, with further prompts that could fine-tune the output in each of them. The ability to install its own dependencies can be achieved through Dockerization or Nix. Finally, the use of agents that autonomously run the code in a loop and watch the prompt file can be helpful.",10,10
What architectural changes would make this better?,https://github.com/smol-ai/developer,"- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,body {
  font-family: Arial, sans-serif;
  margin: 0;
  padding: 15px;
}

textarea, input {
  display: block;
  width: 100%;
  margin-bottom: 10px;
  padding: 5px;
  font-size: 14px;
}

button {
  background-color: #4CAF50;
  border: none;
  color: white;
  padding: 10px 20px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 14px;
  margin: 10px 0;
  cursor: pointer;
}

button:hover {
  background-color: #45a049;
}

#content {
  margin-top: 20px;
  font-size: 14px;
  line-height: 1.5;
}

#loadingIndicator {
  display: none;
  font-size: 14px;
  color: #999;
},# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**","To improve the performance of the code repository, some architectural changes can be made. One suggestion is to dockerize or use a web container to avoid dependency issues. Another idea is to implement self-healing by running the code and using errors as information for reprompting. Additionally, using anthropic as the coding layer can be explored. Making agents that autonomously run the code in a loop and regenerate code each time on a new git branch is another possibility. The use of Markdown for prompts and copy-paste programming can also be helpful. Debugging by catting the whole codebase with error messages and getting specific fix suggestions is a useful trick. Finally, ensuring whole program coherence by specifying dependencies and using clear communication is important.",50,11
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,modal-client
openai
tiktoken","Converting the Github repository into a CLI can have potential benefits such as avoiding dependency issues and enabling self-healing. This can be achieved efficiently by using tools like Docker or Nix. Additionally, Markdown can be used for whole program synthesis and copy-paste programming can be used to teach the program to understand new APIs. Debugging can be done by ""cat""ing the whole codebase with error messages and getting specific fix suggestions. Future directions include specifying .md files for each generated file and bootstrapping the prompt.md for existing codebases. The AI is only used as long as it adds value and can be taken over by the developer when necessary. This approach represents a higher order evolution of programming where technical knowledge is still required but not every detail needs to be implemented.",20,0
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches","Yes, it is possible to refactor the code to create a more user-friendly CLI interface. The `smol developer` repository provides a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The codebase is simple, safe, and small, making it easy to understand and customize. The `prompt.md` file shows the potential of an AI-enabled, but still firmly human developer-centric workflow. The user can simply add to the prompt as they discover underspecified parts of the prompt. The repository also suggests future directions, such as specifying .md files for each generated file and the ability to install its own dependencies. However, it is important to note that the social and technical impacts of multilayer generative deep-frying of codebases should be considered.",70,1
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections","To convert the existing code into a CLI application, changes need to be made to the codebase. The `smol developer` repository contains a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The `main.py` file generates code based on the prompt specified in `prompt.md`. The generated code can be manually run and errors can be identified by pasting the error into the prompt. The `debugger.py` file can also be used to make specific code change suggestions. The `smol developer` is a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.",70,2
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface, you can use the ""smol developer"" agent in this repository. This agent scaffolds an entire codebase based on a product spec provided by the user. The codebase is generated using prompts and GPT-4, and can be fine-tuned by the user through a tight loop with the agent. The generated code can be run and read by the user, who can then add to the prompt as they discover underspecified parts of it. The agent is human-centric and aims to complement the user's technical abilities. Future directions for the agent include specifying .md files for each generated file, bootstrapping the prompt for existing codebases, and making agents that autonomously run the code in a loop.",50,3
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface (CLI) for better usability, one can use the `smol developer` tool available in the `smol-ai/developer` repository. The tool is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The `main.py` file generates code based on the prompt specified in `prompt.md`. To add a CLI, one can modify the prompt to include the necessary specifications for the CLI and run `main.py` again to generate the updated code. The tool uses AI to generate code based on the prompt, but the human is still in control and can add to the prompt as needed. The generated code can be run and tested by the human, who can then modify the prompt to make further changes. The tool is designed to be simple, safe, and customizable, with less than 200 lines of Python and Prompts.",80,4
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface, one can use the ""smol developer"" agent, which scaffolds an entire codebase based on a product spec. The agent uses prompts to generate code, and the generated code can be run and modified by a human developer. The agent can be further improved by specifying .md files for each generated file, bootstrapping the prompt for existing codebases, and making agents that autonomously run the code in a loop. However, there are challenges such as installing dependencies and ensuring whole program coherence. The agent is a prototype and is still being developed.",70,5
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface (CLI) for easier usage, one can use the `smol developer` tool available in this repository. The tool is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec. The `main.py` file generates code based on the prompt specified in `prompt.md`. To add CLI functionality, one can modify the prompt to include the necessary commands and options. The tool uses AI to generate code based on the prompt, but the human developer can add to the prompt as they discover underspecified parts of the prompt. The generated code can be run and read by the human developer, who can make further modifications to the prompt as needed. The tool is designed to be simple, safe, and smol, with less than 200 lines of Python and Prompts, making it easy to understand and customize.",80,6
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface, one can use the ""smol developer"" agent, which is a prototype of a junior developer that scaffolds an entire codebase out for you once you give it a product spec. The agent uses prompts to generate code, and the generated code can be run and read by a human who can add to the prompt as they discover underspecified parts of it. The agent can also be used to bootstrap the prompt for existing codebases. The codebase for the ""smol developer"" agent is simple, safe, and less than 200 lines of Python and Prompts, making it easy to understand and customize.",0,7
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface (CLI) for better usability, one can use the `smol developer` agent. This agent scaffolds an entire codebase out for you once you give it a product spec. The `main.py` file generates code based on the prompt written by the human. The generated code can be run and read by the human who can add to the prompt as they discover underspecified parts of it. The `smol developer` is a prototype of a ""junior developer"" agent that is helpful, harmless, and honest. It is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so it is easy to understand and customize. The `smol developer` uses prompts to generate code, making it a human-centric and coherent whole program synthesis tool.",50,8
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","Converting the codebase into a CLI can have potential benefits such as avoiding dependency issues by dockerizing or using Nix, self-healing by using errors as information for reprompting, using anthropic as the coding layer, and making agents that autonomously run the code in a loop. Markdown can be used to prompt for whole program synthesis, and copy and paste programming can be used to teach the program to understand how to code around a new API. Debugging can be done by ""cat""ing the whole codebase with the error message and getting specific fix suggestions. Future directions include specifying .md files for each generated file, bootstrapping the prompt.md for existing codebases, and adding dependencies to the prompt as they are discovered. Smol developer is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec.",20,9
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","To convert the existing codebase into a command-line interface, one can use the ""smol developer"" agent, which scaffolds an entire codebase based on a product spec. The agent uses AI to generate code based on prompts written by a human, and the generated code can be run and modified by the human as needed. The agent is designed to be helpful, harmless, and honest, and the codebase is simple, safe, and small. The agent can be customized and extended using prompts, and future directions include specifying .md files for each generated file, bootstrapping the prompt for existing codebases, and making agents that autonomously run the code in a loop.",0,10
How can we refactor to make this a CLI?,https://github.com/smol-ai/developer,"- **ability to install its own dependencies**
  - this leaks into depending on the execution environment, which we all know is the path to dependency madness. how to avoid? dockerize? nix? [web container](https://twitter.com/litbid/status/1658154530385670150)?
  - Modal has an interesting possibility: generate functions that speak modal which also solves the dependency thing https://twitter.com/akshat_b/status/1658146096902811657
- **self-heal** by running the code itself and use errors as information for reprompting 
  - however its a bit hard to get errors from the chrome extension environment so we did not try this
- **using anthropic as the coding layer**
  - you can run `modal run anthropic.py --prompt prompt.md --outputdir=anthropic` to try it
  - but it doesnt work because anthropic doesnt follow instructions to generate file code very well.
- **make agents that autonomously run this code in a loop/watch the prompt file** and regenerate code each time, on a new git branch
  - the code could be generated on 5 simultaneous git branches and checking their output would just involve switching git branches,- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \`\`\` code fenced code samples)
  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter
- **Copy and paste programming**
  - teaching the program to understand how to code around a new API (Anthropic's API is after GPT3's knowledge cutoff) by just pasting in the `curl` input and output
  - pasting error messages into the prompt and vaguely telling the program how you'd like it handled. it kind of feels like ""logbook driven programming"".
- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!
- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. 
  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...
  - ... but it's not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it's just clear unambiguous communication at the end of the day. 
  - see `prompt.md` for SOTA smol-dev prompting
- **Low activation energy for unfamiliar APIs**,```bash
# add prompt... this needed a few iterations to get right
modal run code2prompt.py --prompt ""make sure all the id's of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code"" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase

# must go deeper
modal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code
```

We leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.

## future directions

things to try/would accept open issue discussions and PRs:

- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them
  - so basically like `popup.html.md` and `content_script.js.md` and so on
- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it
  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao
- **ability to install its own dependencies**,- simply add to the prompt as they discover underspecified parts of the prompt
  - manually runs the code and identifies errors
  - *paste the error into the prompt* just like they would file a github issue
  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions

Loop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)

*Not no code, not low code, but some third thing.* 

Perhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.

## video demo

[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)

## arch diagram

naturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)
![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)


### innovations and insights

> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections,# smol developer

***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer

> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation

this is a prototype of a ""junior developer"" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.

AI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.

<p align=""center"">
  <img height=200 src=""https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large"" />
</p>


*engineering with prompts, rather than prompt engineering* 

The demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:

- Human writes a basic prompt for the app they want to build
- `main.py` generates code
- Human runs/reads the code
- Human can:
  - simply add to the prompt as they discover underspecified parts of the prompt","Converting the codebase to a CLI can have potential benefits such as the ability to install its own dependencies and self-healing by running the code itself. However, this may lead to dependency issues and can be avoided by dockerizing or using Nix. Another possibility is to generate functions that speak modal to solve the dependency problem. Additionally, Markdown can be used to prompt for whole program synthesis and copy and paste programming can be used to teach the program to understand how to code around a new API. Debugging can be done by ""cat""ing the whole codebase with the error message and getting specific fix suggestions. To achieve this efficiently, agents can be made to autonomously run the code in a loop and regenerate code each time on a new git branch. Future directions include specifying .md files for each generated file and bootstrapping the prompt.md for existing codebases. Smol developer is a prototype of a ""junior developer"" agent that scaffolds an entire codebase out for you once you give it a product spec.",20,11
