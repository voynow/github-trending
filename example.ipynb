{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voyno\\Desktop\\code\\repos\\repo-chat\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import repo_chat.git2vectors as git2vectors\n",
    "from repo_chat.chat_utils import RetrievalChain\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore, this will take a while\n",
    "repo = \"https://github.com/smol-ai/developer\"\n",
    "# git2vectors.create_vectorstore(repo)\n",
    "\n",
    "# load vectorstore, this is fas\n",
    "vectorstore = git2vectors.get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# smol developer\\r\\n\\r\\n***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer\\r\\n\\r\\n> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation\\r\\n\\r\\nthis is a prototype of a \"junior developer\" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.\\r\\n\\r\\nAI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.\\r\\n\\r\\n<p align=\"center\">\\r\\n  <img height=200 src=\"https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large\" />\\r\\n</p>\\r\\n\\r\\n\\r\\n*engineering with prompts, rather than prompt engineering* \\r\\n\\r\\nThe demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:\\r\\n\\r\\n- Human writes a basic prompt for the app they want to build\\r\\n- `main.py` generates code\\r\\n- Human runs/reads the code\\r\\n- Human can:\\r\\n  - simply add to the prompt as they discover underspecified parts of the prompt', '<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\r\\n  <title>Anthropic Summary</title>\\r\\n  <link rel=\"stylesheet\" href=\"styles.css\">\\r\\n</head>\\r\\n<body>\\r\\n  <div id=\"content\"></div>\\r\\n  <div id=\"loadingIndicator\"></div>\\r\\n  <textarea id=\"userPrompt\"></textarea>\\r\\n  <button id=\"sendButton\">Submit</button>\\r\\n  <script src=\"popup.js\"></script>\\r\\n</body>\\r\\n</html>', \"- simply add to the prompt as they discover underspecified parts of the prompt\\r\\n  - manually runs the code and identifies errors\\r\\n  - *paste the error into the prompt* just like they would file a github issue\\r\\n  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions\\r\\n\\r\\nLoop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)\\r\\n\\r\\n*Not no code, not low code, but some third thing.* \\r\\n\\r\\nPerhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.\\r\\n\\r\\n## video demo\\r\\n\\r\\n[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)\\r\\n\\r\\n## arch diagram\\r\\n\\r\\nnaturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)\\r\\n![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)\\r\\n\\r\\n\\r\\n### innovations and insights\\r\\n\\r\\n> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections\", 'modal-client\\r\\nopenai\\r\\ntiktoken', 'body {\\r\\n  font-family: Arial, sans-serif;\\r\\n  margin: 0;\\r\\n  padding: 15px;\\r\\n}\\r\\n\\r\\ntextarea, input {\\r\\n  display: block;\\r\\n  width: 100%;\\r\\n  margin-bottom: 10px;\\r\\n  padding: 5px;\\r\\n  font-size: 14px;\\r\\n}\\r\\n\\r\\nbutton {\\r\\n  background-color: #4CAF50;\\r\\n  border: none;\\r\\n  color: white;\\r\\n  padding: 10px 20px;\\r\\n  text-align: center;\\r\\n  text-decoration: none;\\r\\n  display: inline-block;\\r\\n  font-size: 14px;\\r\\n  margin: 10px 0;\\r\\n  cursor: pointer;\\r\\n}\\r\\n\\r\\nbutton:hover {\\r\\n  background-color: #45a049;\\r\\n}\\r\\n\\r\\n#content {\\r\\n  margin-top: 20px;\\r\\n  font-size: 14px;\\r\\n  line-height: 1.5;\\r\\n}\\r\\n\\r\\n#loadingIndicator {\\r\\n  display: none;\\r\\n  font-size: 14px;\\r\\n  color: #999;\\r\\n}']\n",
      "['# smol developer\\r\\n\\r\\n***Human-centric & Coherent Whole Program Synthesis*** aka your own personal junior developer\\r\\n\\r\\n> [Build the thing that builds the thing!](https://twitter.com/swyx/status/1657578738345979905) a `smol dev` for every dev in every situation\\r\\n\\r\\nthis is a prototype of a \"junior developer\" agent (aka `smol dev`) that scaffolds an entire codebase out for you once you give it a product spec, but does not end the world or overpromise AGI. instead of making and maintaining specific, rigid, one-shot starters, like `create-react-app`, or `create-nextjs-app`, this is basically [`create-anything-app`](https://news.ycombinator.com/item?id=35942352) where you develop your scaffolding prompt in a tight loop with your smol dev.\\r\\n\\r\\nAI that is helpful, harmless, and honest is complemented by a codebase that is simple, safe, and smol - <200 lines of Python and Prompts, so this is easy to understand and customize.\\r\\n\\r\\n<p align=\"center\">\\r\\n  <img height=200 src=\"https://pbs.twimg.com/media/FwEzVCcaMAE7t4h?format=jpg&name=large\" />\\r\\n</p>\\r\\n\\r\\n\\r\\n*engineering with prompts, rather than prompt engineering* \\r\\n\\r\\nThe demo example in `prompt.md` shows the potential of AI-enabled, but still firmly human developer centric, workflow:\\r\\n\\r\\n- Human writes a basic prompt for the app they want to build\\r\\n- `main.py` generates code\\r\\n- Human runs/reads the code\\r\\n- Human can:\\r\\n  - simply add to the prompt as they discover underspecified parts of the prompt', \"- simply add to the prompt as they discover underspecified parts of the prompt\\r\\n  - manually runs the code and identifies errors\\r\\n  - *paste the error into the prompt* just like they would file a github issue\\r\\n  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions\\r\\n\\r\\nLoop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)\\r\\n\\r\\n*Not no code, not low code, but some third thing.* \\r\\n\\r\\nPerhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.\\r\\n\\r\\n## video demo\\r\\n\\r\\n[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)\\r\\n\\r\\n## arch diagram\\r\\n\\r\\nnaturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)\\r\\n![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)\\r\\n\\r\\n\\r\\n### innovations and insights\\r\\n\\r\\n> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections\", '## install\\r\\n\\r\\nit\\'s basically: \\r\\n\\r\\n- `git clone https://github.com/smol-ai/developer`.\\r\\n- copy over `.example.env` to `.env` filling in your API keys.\\r\\n\\r\\nThere are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).\\r\\n\\r\\nUnfortunately this project also uses 3 waitlisted things:\\r\\n\\r\\n- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)\\r\\n  - You can run this project w/o Modal following these instructions:\\r\\n  - `pip install -r requirements.txt`\\r\\n  - `python main_no_modal.py YOUR_PROMPT_HERE`\\r\\n- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good\\r\\n- (for the demo project) anthropic claude 100k context api (private beta)\\r\\n\\r\\n> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword \"swyx\"\\r\\n\\r\\nyou\\'ll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i\\'ll happily highlight your fork here.\\r\\n\\r\\n### trying the example chrome extension', '- **Markdown is all you need** - Markdown is the perfect way to prompt for whole program synthesis because it is easy to mix english and code (whether `variable_names` or entire \\\\`\\\\`\\\\` code fenced code samples)\\r\\n  - turns out you can specify prompts in code in prompts and gpt4 obeys that to the letter\\r\\n- **Copy and paste programming**\\r\\n  - teaching the program to understand how to code around a new API (Anthropic\\'s API is after GPT3\\'s knowledge cutoff) by just pasting in the `curl` input and output\\r\\n  - pasting error messages into the prompt and vaguely telling the program how you\\'d like it handled. it kind of feels like \"logbook driven programming\".\\r\\n- **Debugging by `cat`ing** the whole codebase with your error message and getting specific fix suggestions - particularly delightful!\\r\\n- **Tricks for whole program coherence** - our chosen example usecase, Chrome extensions, have a lot of indirect dependencies across files. Any hallucination of cross dependencies causes the whole program to error. \\r\\n  - We solved this by adding an intermediate step asking GPT to think through `shared_dependencies.md`, and then insisting on using that in generating each file. This basically means GPT is able to talk to itself...\\r\\n  - ... but it\\'s not perfect, yet. `shared_dependencies.md` is sometimes not comperehensive in understanding what are hard dependencies between files. So we just solved it by specifying a specific `name` in the prompt. felt dirty at first but it works, and really it\\'s just clear unambiguous communication at the end of the day. \\r\\n  - see `prompt.md` for SOTA smol-dev prompting\\r\\n- **Low activation energy for unfamiliar APIs**', \"The program is a Chrome extension that summarizes web pages using the Anthropic Claude API. It consists of several files: popup.js, styles.css, \\r\\nbackground.js, popup.html, shared_dependencies.md, and content_script.js. \\r\\n\\r\\npopup.html is the main user interface for the extension, containing a form with several input fields and a submit button. popup.js handles the logic\\r\\nfor the form, including retrieving the user's input, calling the Anthropic API, and rendering the summary in the content div. styles.css provides \\r\\nstyling for the UI elements.\\r\\n\\r\\nbackground.js is responsible for executing content_script.js, which retrieves the page content (title and body text) and sends it to popup.js for \\r\\nprocessing. It also handles storing and retrieving the page content data using Chrome's storage API.\\r\\n\\r\\nshared_dependencies.md lists the shared variables, data schemas, DOM element IDs, message names, and function names used across the various files.\\r\\n\\r\\nOverall, the program uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface for summarizing web pages using the \\r\\nAnthropic Claude API.\"]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This github repository contains a prototype for a \"junior developer\" agent that scaffolds an entire codebase for you based on a product spec. It is a human-centric and coherent whole program synthesis tool that uses AI to assist in the development process. The codebase is simple, safe, and small, making it easy to understand and customize. The demo example shows how the tool works by allowing the user to write a basic prompt for the app they want to build, generating code, and then manually running the code and identifying errors. The AI is only used as long as it is adding value, and the user can take over the codebase from the \"junior developer\" at any time. The tool is not no code or low code, but rather a third thing that still requires technical knowledge. The repository also includes a video demo and an architecture diagram. The tool requires Modal.com, GPT-4 API, and anthropic claude 100k context API, which are currently in private beta. The example project is a Chrome extension that summarizes web pages using the Anthropic Claude API."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "chain = RetrievalChain(vectorstore, repo)\n",
    "\n",
    "# Let's say we have a query\n",
    "query = \"Explain this to me like I\\'m 5.\"\n",
    "\n",
    "# generic retrieval query\n",
    "response = chain.chat(query)\n",
    "Markdown(response['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
