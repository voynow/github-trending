{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voyno\\Desktop\\code\\repos\\repo-chat\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import git2vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from git repo...\n",
      "Clearing index testindex from previous runs...\n",
      "Done!\n",
      "\n",
      "describe_index_stats:\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.1,\n",
      " 'namespaces': {'': {'vector_count': 4196}},\n",
      " 'total_vector_count': 4196}\n"
     ]
    }
   ],
   "source": [
    "repo = \"https://github.com/hwchase17/langchain\"\n",
    "vectorstore = git2vectors.create_vectorstore(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=git2vectors.OPENAI_API_KEY,\n",
    "    model_name='gpt-4',\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "template=\"\"\"A user is asking a question about a code repository. Here is there query:\n",
    "{query}\n",
    "\n",
    "Here are some documents containing similar information to the query:\n",
    "{similar_documents}\n",
    "\n",
    "If you don't know say \"idk\" else answer the question.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"similar_documents\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To count the tokens in a PromptTemplate, you can use the `len()` function in Python. First, you need to convert the PromptTemplate into a string, and then split the string into tokens (words). Here's an example:\n",
      "\n",
      "```python\n",
      "from langchain.prompts.prompt import PromptTemplate\n",
      "\n",
      "template = (\n",
      "    \"\"\"Question: {question}\n",
      "    Answer: Let's think step by step.\"\"\"\n",
      ")\n",
      "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
      "\n",
      "# Convert the PromptTemplate to a string\n",
      "template_str = str(prompt)\n",
      "\n",
      "# Split the string into tokens (words)\n",
      "tokens = template_str.split()\n",
      "\n",
      "# Count the tokens\n",
      "token_count = len(tokens)\n",
      "\n",
      "print(\"Token count:\", token_count)\n",
      "```\n",
      "\n",
      "This code will output the number of tokens in the given PromptTemplate.\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I count the tokens in a PromptTemplate?\"\n",
    "\n",
    "similarity_resp = vectorstore.similarity_search_with_score(\n",
    "    query, k=10\n",
    ")\n",
    "\n",
    "chain_inputs = {\n",
    "    \"query\" : query,\n",
    "    \"similar_documents\": [doc.page_content for doc, _ in similarity_resp]\n",
    "}\n",
    "chain_resp = chain(chain_inputs)\n",
    "\n",
    "if \"idk\" in chain_resp['text']:\n",
    "    print(\"RAG FAILED\")\n",
    "else:\n",
    "    print(chain_resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_str = prompt.template\n",
    "# for var in prompt.input_variables:\n",
    "#     template_str.replace(\"{var}\", \"\")\n",
    "\n",
    "# # count number of tokens in template_str\n",
    "# import tiktoken\n",
    "# tokenizer = tiktoken.Tokenizer()\n",
    "# tokenizer.tokenize(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
