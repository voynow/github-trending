{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voyno\\Desktop\\code\\repos\\repo-chat\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import git2vectors\n",
    "import chat_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from git repo...\n",
      "Clearing index testindex from previous runs...\n",
      "Done!\n",
      "\n",
      "describe_index_stats:\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.1,\n",
      " 'namespaces': {'': {'vector_count': 4196}},\n",
      " 'total_vector_count': 4196}\n"
     ]
    }
   ],
   "source": [
    "repo = \"https://github.com/hwchase17/langchain\"\n",
    "vectorstore = git2vectors.create_vectorstore(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the LangChain library, you need to first install it and then import it into your Python script. Here's a simple example of how to use LangChain with a language model:\n",
      "\n",
      "1. Install LangChain using pip:\n",
      "```\n",
      "pip install langchain\n",
      "```\n",
      "\n",
      "2. Import LangChain and other necessary libraries in your Python script:\n",
      "```python\n",
      "from langchain import LangChain\n",
      "from langchain.prompt_templates import PromptTemplate\n",
      "```\n",
      "\n",
      "3. Initialize the LangChain instance with your desired language model (e.g., GPT-3):\n",
      "```python\n",
      "lc = LangChain(model=\"gpt-3\")\n",
      "```\n",
      "\n",
      "4. Create a PromptTemplate for your task. For example, let's create a template for a simple question-answering task:\n",
      "```python\n",
      "qa_template = PromptTemplate(\n",
      "    prompt=\"Question: {question}\\nAnswer:\",\n",
      "    tokens=100,\n",
      "    temperature=0.5,\n",
      ")\n",
      "```\n",
      "\n",
      "5. Use the LangChain instance to generate a response using the prompt template:\n",
      "```python\n",
      "question = \"What is the capital of France?\"\n",
      "response = lc.generate(qa_template, question=question)\n",
      "```\n",
      "\n",
      "6. Print the generated response:\n",
      "```python\n",
      "print(response)\n",
      "```\n",
      "\n",
      "This example demonstrates how to use LangChain with a simple question-answering task. You can create more complex applications by using different prompt templates, chaining multiple calls, and integrating with other data sources. For more examples and tutorials, refer to the [LangChain documentation](https://langchain.readthedocs.io/en/latest/).\n",
      "Tokens Used: 1988\n",
      "\tPrompt Tokens: 1673\n",
      "\tCompletion Tokens: 315\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.06909\n"
     ]
    }
   ],
   "source": [
    "chain = chat_utils.construct_chain(git2vectors.OPENAI_API_KEY)\n",
    "\n",
    "Q = \"How do I use the Langchain library? Give an example.\"\n",
    "inputs, docs = chat_utils.get_chain_inputs(vectorstore, Q)\n",
    "\n",
    "chat_utils.chat(chain, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
