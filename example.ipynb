{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voyno\\Desktop\\code\\repos\\repo-chat\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import git2vectors\n",
    "from chat_utils import RetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore, this will take a while\n",
    "repo = \"https://github.com/smol-ai/developer\"\n",
    "git2vectors.create_vectorstore(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorstore, this is fast\n",
    "vectorstore = git2vectors.get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I use this?\n",
      "Inadequate context. Please provide more information about the code repository and what you are trying to accomplish with it.\n",
      "['modal-client\\r\\nopenai\\r\\ntiktoken', 'body {\\r\\n  font-family: Arial, sans-serif;\\r\\n  margin: 0;\\r\\n  padding: 15px;\\r\\n}\\r\\n\\r\\ntextarea, input {\\r\\n  display: block;\\r\\n  width: 100%;\\r\\n  margin-bottom: 10px;\\r\\n  padding: 5px;\\r\\n  font-size: 14px;\\r\\n}\\r\\n\\r\\nbutton {\\r\\n  background-color: #4CAF50;\\r\\n  border: none;\\r\\n  color: white;\\r\\n  padding: 10px 20px;\\r\\n  text-align: center;\\r\\n  text-decoration: none;\\r\\n  display: inline-block;\\r\\n  font-size: 14px;\\r\\n  margin: 10px 0;\\r\\n  cursor: pointer;\\r\\n}\\r\\n\\r\\nbutton:hover {\\r\\n  background-color: #45a049;\\r\\n}\\r\\n\\r\\n#content {\\r\\n  margin-top: 20px;\\r\\n  font-size: 14px;\\r\\n  line-height: 1.5;\\r\\n}\\r\\n\\r\\n#loadingIndicator {\\r\\n  display: none;\\r\\n  font-size: 14px;\\r\\n  color: #999;\\r\\n}', '<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n  <meta charset=\"UTF-8\">\\r\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\r\\n  <title>Anthropic Summary</title>\\r\\n  <link rel=\"stylesheet\" href=\"styles.css\">\\r\\n</head>\\r\\n<body>\\r\\n  <div id=\"content\"></div>\\r\\n  <div id=\"loadingIndicator\"></div>\\r\\n  <textarea id=\"userPrompt\"></textarea>\\r\\n  <button id=\"sendButton\">Submit</button>\\r\\n  <script src=\"popup.js\"></script>\\r\\n</body>\\r\\n</html>', '<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n<head>\\r\\n    <meta charset=\"UTF-8\">\\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\r\\n    <title>Anthropic Claude Summary Extension</title>\\r\\n    <link rel=\"stylesheet\" href=\"styles.css\">\\r\\n</head>\\r\\n<body>\\r\\n    <form>\\r\\n        <label for=\"userPrompt\">User Prompt:</label>\\r\\n        <textarea id=\"userPrompt\"></textarea>\\r\\n        <label for=\"stylePrompt\">Style Prompt:</label>\\r\\n        <textarea id=\"stylePrompt\"></textarea>\\r\\n        <label for=\"maxTokens\">Max Tokens:</label>\\r\\n        <input type=\"number\" id=\"maxTokens\">\\r\\n        <button type=\"button\" id=\"sendButton\">Request Summary</button>\\r\\n    </form>\\r\\n    <div id=\"content\"></div>\\r\\n    <div id=\"loadingIndicator\" style=\"display:none;\"></div>\\r\\n    <script src=\"popup.js\"></script>\\r\\n</body>\\r\\n</html>', '- at the bottom of the popup, show a vertically resizable form that has:\\r\\n      - a 2 line textarea with an id and label of `userPrompt`\\r\\n        - `userPrompt` has a default value of\\r\\n            ```js\\r\\n            defaultPrompt = `Please provide a detailed, easy to read HTML summary of the given content`;\\r\\n            ```js\\r\\n      - a 4 line textarea with an id and label of `stylePrompt`\\r\\n        - `stylePrompt` has a default value of\\r\\n            ```js\\r\\n            defaultStyle = `Respond with 3-4 highlights per section with important keywords, people, numbers, and facts bolded in this HTML format:\\r\\n            \\r\\n            <h1>{title here}</h1>\\r\\n            <h3>{section title here}</h3>\\r\\n            <details>\\r\\n              <summary>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</summary>\\r\\n              <ul>\\r\\n                <li><strong>{first point}</strong>: {short explanation with <strong>important keywords, people, numbers, and facts bolded</strong>}</li>\\r\\n                <li><strong>{second point}</strong>: {same as above}</li>\\r\\n                <li><strong>{third point}</strong>: {same as above}</li>\\r\\n                <!-- a fourth point if warranted -->\\r\\n              </ul>\\r\\n            </details>\\r\\n            <h3>{second section here}</h3>\\r\\n            <p>{summary of the section with <strong>important keywords, people, numbers, and facts bolded</strong> and key quotes repeated}</p>\\r\\n            <details>']\n",
      "[0.750383377, 0.747638, 0.746604145, 0.74243474, 0.741861045]\n",
      "Tokens Used: 1183\n",
      "\tPrompt Tokens: 1160\n",
      "\tCompletion Tokens: 23\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.002366\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "chain = RetrievalChain(\n",
    "    git2vectors.OPENAI_API_KEY, vectorstore)\n",
    "\n",
    "# Let's say we have a query\n",
    "query = \"How do I use this?\"\n",
    "\n",
    "# generic retrieval query\n",
    "response = chain.chat(query)\n",
    "\n",
    "print(response['query'])\n",
    "print(response['text'])\n",
    "print(response['similar_documents'])\n",
    "print(response['scores'])\n",
    "print(response['callback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you provide instructions on how to use this code repository?\n",
      "Inadequate context. The documents provided do not contain specific instructions on how to use a code repository. Can you please provide more information about the repository in question?\n",
      "[\"- simply add to the prompt as they discover underspecified parts of the prompt\\r\\n  - manually runs the code and identifies errors\\r\\n  - *paste the error into the prompt* just like they would file a github issue\\r\\n  - for extra help, they can use `debugger.py` which reads the whole codebase to make specific code change suggestions\\r\\n\\r\\nLoop until happiness is attained. Notice that AI is only used as long as it is adding value - once it gets in your way, just take over the codebase from your smol junior developer with no fuss and no hurt feelings. (*we could also have smol-dev take over an existing codebase and bootstrap its own prompt... but that's a Future Direction*)\\r\\n\\r\\n*Not no code, not low code, but some third thing.* \\r\\n\\r\\nPerhaps a higher order evolution of programming where you still need to be technical, but no longer have to implement every detail at least to scaffold things out.\\r\\n\\r\\n## video demo\\r\\n\\r\\n[![https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg](https://i3.ytimg.com/vi/UCo7YeTy-aE/hqdefault.jpg)](https://youtu.be/UCo7YeTy-aE)\\r\\n\\r\\n## arch diagram\\r\\n\\r\\nnaturally generated with gpt4, like [we did for babyagi](https://twitter.com/swyx/status/1648724820316786688)\\r\\n![image](https://github.com/smol-ai/developer/assets/6764957/f8fc68f4-77f6-43ee-852f-a35fb195430a)\\r\\n\\r\\n\\r\\n### innovations and insights\\r\\n\\r\\n> Please subscribe to https://latent.space/ for a fuller writeup and insights and reflections\", '## install\\r\\n\\r\\nit\\'s basically: \\r\\n\\r\\n- `git clone https://github.com/smol-ai/developer`.\\r\\n- copy over `.example.env` to `.env` filling in your API keys.\\r\\n\\r\\nThere are no python dependencies to wrangle thanks to using Modal as a [self-provisioning runtime](https://www.google.com/search?q=self+provisioning+runtime).\\r\\n\\r\\nUnfortunately this project also uses 3 waitlisted things:\\r\\n\\r\\n- Modal.com - `pip install modal-client` (private beta - hit up the modal team to get an invite, and login)\\r\\n  - You can run this project w/o Modal following these instructions:\\r\\n  - `pip install -r requirements.txt`\\r\\n  - `python main_no_modal.py YOUR_PROMPT_HERE`\\r\\n- GPT-4 api (private beta) - can use 3.5 but obviously wont be as good\\r\\n- (for the demo project) anthropic claude 100k context api (private beta)\\r\\n\\r\\n> yes, the most important skill in being an ai engineer is social engineering to get off waitlists. Modal will let you in if you say the keyword \"swyx\"\\r\\n\\r\\nyou\\'ll have to adapt this code on a fork if you want to use it on other infra. please open issues/PRs and i\\'ll happily highlight your fork here.\\r\\n\\r\\n### trying the example chrome extension', 'OPENAI_API_KEY=sk-xxxxxx\\r\\nANTHROPIC_API_KEY=sk-ant-api03-xxxxxx', '```bash\\r\\n# add prompt... this needed a few iterations to get right\\r\\nmodal run code2prompt.py --prompt \"make sure all the id\\'s of the DOM elements, and the data structure of the page content (stored with {pageTitle, pageContent }) , referenced/shared by the js files match up exactly. take note to only use Chrome Manifest V3 apis. rename the extension to code2prompt2code\" --model=gpt-4 # takes 4 mins. produces semi working chrome extension copy based purely on the model-generated description of a different codebase\\r\\n\\r\\n# must go deeper\\r\\nmodal run main.py --prompt code2prompt-gpt4.md --directory code2prompt2code\\r\\n```\\r\\n\\r\\nWe leave the social and technical impacts of multilayer generative deep-frying of codebases as an exercise to the reader.\\r\\n\\r\\n## future directions\\r\\n\\r\\nthings to try/would accept open issue discussions and PRs:\\r\\n\\r\\n- **specify .md files for each generated file**, with further prompts that could finetune the output in each of them\\r\\n  - so basically like `popup.html.md` and `content_script.js.md` and so on\\r\\n- **bootstrap the `prompt.md`** for existing codebases - write a script to read in a codebase and write a descriptive, bullet pointed prompt that generates it\\r\\n  - done by `smol pm`, but its not very good yet - would love for some focused polish/effort until we have quine smol developer that can generate itself lmao\\r\\n- **ability to install its own dependencies**', 'modal-client\\r\\nopenai\\r\\ntiktoken']\n",
      "[0.769628942, 0.76272589, 0.761504173, 0.760183752, 0.750939071]\n",
      "Tokens Used: 1217\n",
      "\tPrompt Tokens: 1184\n",
      "\tCompletion Tokens: 33\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.002434\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the class (with upgrade query)\n",
    "chain = RetrievalChain(\n",
    "    git2vectors.OPENAI_API_KEY, vectorstore, upgrade=True)\n",
    "\n",
    "# Let's say we have a query\n",
    "query = \"How do I use this?\"\n",
    "\n",
    "# retrieval query with query upgrade augmentation\n",
    "response = chain.chat(query)\n",
    "\n",
    "print(response['query'])\n",
    "print(response['text'])\n",
    "print(response['similar_documents'])\n",
    "print(response['scores'])\n",
    "print(response['callback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
