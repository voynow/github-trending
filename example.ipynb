{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voyno\\Desktop\\code\\repos\\repo-chat\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from git2vec import vectordb, loader\n",
    "from repo_chat.chat_utils import RetrievalChain, RawChain\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore, this will take a while\n",
    "repo_name = \"https://github.com/smol-ai/developer\"\n",
    "vectordb.create_vectorstore(repo_name)\n",
    "\n",
    "# load vectorstore, this is fast\n",
    "vectorstore = vectordb.get_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This github repository contains a prototype for a \"junior developer\" agent that scaffolds an entire codebase based on a product spec. It is designed to be helpful, harmless, and honest, with a codebase that is simple, safe, and small. The program uses prompts to generate code, and the user can manually run and identify errors, or paste the error into the prompt to file a github issue. The program is a Chrome extension that summarizes web pages using the Anthropic Claude API, and uses a combination of JavaScript, HTML, and CSS to provide a user-friendly interface. The repository also includes a video demo and an architecture diagram."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the class\n",
    "chain = RetrievalChain(vectorstore, repo_name)\n",
    "\n",
    "# Let's say we have a query\n",
    "query = \"Explain this to me like I\\'m 5.\"\n",
    "\n",
    "# generic retrieval query\n",
    "response = chain.chat(query)\n",
    "Markdown(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load the repo data in its entirety\n",
    "repo_name = \"https://github.com/voynow/turbo-docs\"\n",
    "raw_repo = loader.load(repo_name, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use this code, you can follow these steps:\n",
       "\n",
       "1. Clone the repository to your local machine.\n",
       "2. Install the required packages by running `pip install -r requirements.txt`.\n",
       "3. Customize the `exclude.toml` file to exclude any files or directories you do not want to include in the documentation generation.\n",
       "4. Run the `generate.py` script in the `turbo_docs` folder to generate a README.md or docstrings for the current directory. You can use the optional flags `--copy`, `--readme`, and `--docstring` to customize the output. For example, to generate a README.md file and copy the directory text to clipboard, you can run `turbo_docs --readme --copy`.\n",
       "\n",
       "Note that you will need to have an OpenAI API key to use the GPT-3 text completion model. You can set your API key as an environment variable or enter it when prompted by the script."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and pass the entire repo to a raw chain\n",
    "chain = RawChain(raw_repo)\n",
    "\n",
    "# and ask a question\n",
    "response = chain.chat(\"How do I use this?\")\n",
    "Markdown(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
