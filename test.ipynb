{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''\n",
    "import click\n",
    "from pathlib import Path\n",
    "import pyperclip\n",
    "import tiktoken\n",
    "from turbo_docs.commands import readme as readme_module\n",
    "from turbo_docs.commands import docs as docs_module\n",
    "from turbo_docs.utils import directory, cli_options\n",
    "\n",
    "def resolve_model(gpt3):\n",
    "    if gpt3:\n",
    "        model = \"gpt-3.5-turbo-16k\"\n",
    "    else:\n",
    "        model = \"gpt-4\"\n",
    "        print(\n",
    "            \"Warning: This model is under limited beta access and is not available to all users.\"\n",
    "        )\n",
    "        print(\"Warning: GPT-4 api calls tend to be slower than other models.\")\n",
    "\n",
    "    print(f\"Using model: {model}\")\n",
    "    return model\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string, allowed_special=\"all\"))\n",
    "    return num_tokens\n",
    "\n",
    "@click.command()\n",
    "@cli_options.copy\n",
    "@cli_options.readme\n",
    "@cli_options.gpt3\n",
    "@cli_options.docs\n",
    "@cli_options.narrative\n",
    "def driver(\n",
    "    copy: bool,\n",
    "    readme: bool,\n",
    "    gpt3: bool,\n",
    "    docs: bool,\n",
    "    narrative: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Pull text from all files in the current directory and apply the following commands:\n",
    "\n",
    "    'turbo_docs --copy' copies the text to clipboard\n",
    "        Useful for wokring with ChatGPT\n",
    "\n",
    "    'turbo_docs --readme' generates a README.md file\n",
    "        Useful for keeping documentation up to date\n",
    "\n",
    "    'turbo_docs --gpt3' uses GPT-3.5-turbo-16k\n",
    "        Useful if you don't have GPT-4 access\n",
    "\n",
    "    'turbo_docs --docs' generates a docs for each file\n",
    "        Useful for keeping documentation up to date\n",
    "    \"\"\"\n",
    "    dir_text_dict = directory.get_repo_text_dict()\n",
    "\n",
    "    if readme:\n",
    "        if Path(\"README.md\") in dir_text_dict:\n",
    "            del dir_text_dict[Path(\"README.md\")]\n",
    "        dir_text_str = directory.convert_dict_to_string(dir_text_dict)\n",
    "        model = resolve_model(gpt3)\n",
    "        readme_module.readme(dir_text_str, model, narrative=narrative)\n",
    "        print(\"Generated README.md\")\n",
    "\n",
    "    if docs:\n",
    "        model = resolve_model(gpt3)\n",
    "        docs_module.docs(dir_text_dict, model)\n",
    "        print(\"Generated documentation\")\n",
    "\n",
    "    if copy:\n",
    "        dir_text_str = directory.convert_dict_to_string(dir_text_dict)\n",
    "        num_tokens = num_tokens_from_string(dir_text_str)\n",
    "        pyperclip.copy(dir_text_str)\n",
    "        print(f\"Directory text copied to clipboard containing {num_tokens} tokens\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_blocks import blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Here is {filename} from {reponame}:\n",
    "{code}\n",
    "\n",
    "Can you convert this python code to pseudocode? Focus on the high-level logic, not the syntax.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudocode for generate.py:\n",
      "\n",
      "1. Import necessary libraries and modules.\n",
      "2. Define a function named \"resolve_model\" that takes a boolean parameter \"gpt3\".\n",
      "3. Inside the \"resolve_model\" function:\n",
      "   a. Check the value of \"gpt3\".\n",
      "   b. If \"gpt3\" is True, set the variable \"model\" to \"gpt-3.5-turbo-16k\".\n",
      "   c. If \"gpt3\" is False, set the variable \"model\" to \"gpt-4\".\n",
      "   d. Print a warning message if \"gpt3\" is False.\n",
      "   e. Print the selected model.\n",
      "   f. Return the value of \"model\".\n",
      "4. Define a function named \"num_tokens_from_string\" that takes a string parameter \"string\" and an encoding name parameter \"encoding_name\".\n",
      "5. Inside the \"num_tokens_from_string\" function:\n",
      "   a. Get the encoding using the \"encoding_name\".\n",
      "   b. Calculate the number of tokens in the \"string\" using the encoding.\n",
      "   c. Return the number of tokens.\n",
      "6. Define a function named \"driver\" that takes several boolean and string parameters.\n",
      "7. Inside the \"driver\" function:\n",
      "   a. Get the text from all files in the current directory and store it in the \"dir_text_dict\" variable.\n",
      "   b. If the \"readme\" parameter is True:\n",
      "      i. Remove the \"README.md\" key from the \"dir_text_dict\" if it exists.\n",
      "      ii. Convert the \"dir_text_dict\" to a string.\n",
      "      iii. Resolve the model based on the value of \"gpt3\".\n",
      "      iv. Call the \"readme\" function from the \"readme_module\" module with the \"dir_text_str\", \"model\", and \"narrative\" parameters.\n",
      "      v. Print a message indicating that the README.md file has been generated.\n",
      "   c. If the \"docs\" parameter is True:\n",
      "      i. Resolve the model based on the value of \"gpt3\".\n",
      "      ii. Call the \"docs\" function from the \"docs_module\" module with the \"dir_text_dict\" and \"model\" parameters.\n",
      "      iii. Print a message indicating that the documentation has been generated.\n",
      "   d. If the \"copy\" parameter is True:\n",
      "      i. Convert the \"dir_text_dict\" to a string.\n",
      "      ii. Calculate the number of tokens in the \"dir_text_str\".\n",
      "      iii. Copy the \"dir_text_str\" to the clipboard.\n",
      "      iv. Print a message indicating that the directory text has been copied to the clipboard along with the number of tokens.\n",
      "8. Define a click command that calls the \"driver\" function with the appropriate command line options.\n",
      "9. End of the program."
     ]
    }
   ],
   "source": [
    "block = blocks.StreamBlock(template=template)\n",
    "response_generator = block(filename=\"generate.py\", reponame=\"turbo-docs\", code=code)\n",
    "block.display(response_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7pykiJVmnlPkXdgrFPBa1mbi3QuPb\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1692622616,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Pseudocode for generate.py:\\n\\n1. Import necessary libraries and modules.\\n2. Define a function named \\\"resolve_model\\\" that takes a boolean parameter \\\"gpt3\\\".\\n3. Inside the \\\"resolve_model\\\" function:\\n   a. Check the value of \\\"gpt3\\\".\\n   b. If \\\"gpt3\\\" is True, set the variable \\\"model\\\" to \\\"gpt-3.5-turbo-16k\\\".\\n   c. If \\\"gpt3\\\" is False, set the variable \\\"model\\\" to \\\"gpt-4\\\".\\n   d. Print a warning message if \\\"gpt3\\\" is False.\\n   e. Print the selected model.\\n   f. Return the value of \\\"model\\\".\\n4. Define a function named \\\"num_tokens_from_string\\\" that takes a string parameter \\\"string\\\" and an encoding name parameter \\\"encoding_name\\\".\\n5. Inside the \\\"num_tokens_from_string\\\" function:\\n   a. Get the encoding for the specified encoding name.\\n   b. Encode the \\\"string\\\" using the encoding and get the number of tokens.\\n   c. Return the number of tokens.\\n6. Define a function named \\\"driver\\\" that takes several boolean and string parameters.\\n7. Inside the \\\"driver\\\" function:\\n   a. Get the text from all files in the current directory and store it in a dictionary called \\\"dir_text_dict\\\".\\n   b. If the \\\"readme\\\" parameter is True:\\n      i. Remove the \\\"README.md\\\" key from the \\\"dir_text_dict\\\" dictionary if it exists.\\n      ii. Convert the \\\"dir_text_dict\\\" dictionary to a string.\\n      iii. Call the \\\"resolve_model\\\" function with the \\\"gpt3\\\" parameter and store the returned model.\\n      iv. Call the \\\"readme\\\" function from the \\\"readme_module\\\" module with the \\\"dir_text_str\\\", \\\"model\\\", and \\\"narrative\\\" parameters.\\n      v. Print a message indicating that the README.md file has been generated.\\n   c. If the \\\"docs\\\" parameter is True:\\n      i. Call the \\\"resolve_model\\\" function with the \\\"gpt3\\\" parameter and store the returned model.\\n      ii. Call the \\\"docs\\\" function from the \\\"docs_module\\\" module with the \\\"dir_text_dict\\\" and \\\"model\\\" parameters.\\n      iii. Print a message indicating that the documentation has been generated.\\n   d. If the \\\"copy\\\" parameter is True:\\n      i. Convert the \\\"dir_text_dict\\\" dictionary to a string.\\n      ii. Call the \\\"num_tokens_from_string\\\" function with the \\\"dir_text_str\\\" parameter and store the returned number of tokens.\\n      iii. Copy the \\\"dir_text_str\\\" to the clipboard using the \\\"pyperclip\\\" library.\\n      iv. Print a message indicating that the directory text has been copied to the clipboard, along with the number of tokens.\\n8. Define the command-line interface using the \\\"click\\\" library and specify the options for the \\\"copy\\\", \\\"readme\\\", \\\"gpt3\\\", \\\"docs\\\", and \\\"narrative\\\" parameters.\\n9. Call the \\\"driver\\\" function with the specified command-line options.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 613,\n",
      "    \"completion_tokens\": 644,\n",
      "    \"total_tokens\": 1257\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "block = blocks.BatchBlock(template=template, model_name=\"gpt-3.5-turbo\")\n",
    "response = block(filename=\"generate.py\", reponame=\"turbo-docs\", code=code)\n",
    "block.display(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
